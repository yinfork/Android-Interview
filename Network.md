## 计算机网络
<span id = "home"></span>
#### 目录
1. [协议体系模型](#network_arch)
2. [物理层](#network_physical_layer)
3. [数据链路层](#network_data_link_layer)
4. [网络层](#network_network_layer)
5. [运输层](#network_transport_layer)
6. [应用层](#network_application_layer)
6. [总结](#network_summary)

----

<span id = "network_arch"></span>
#### 协议体系模型 [(TOP)](#home)
![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_arch.png?raw=true)

----

<span id = "network_physical_layer"></span>
#### 物理层 [(TOP)](#home)
1. 概述
	1. 作用<br>
		**物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。**
	
	2. 细节<br>
		使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。<br>
	
	3. 数据单位<br>
		在物理层上所传送的数据单位是比特。

2. 传输方向的工作方式
	1. 单工：只能有一个方向的通信而没有反方向的交互。
	2. 半双工：通信的双方都可以发送信息，但不能双方同时发送(当然也就不能同时接收)。
	3. 全双工：通信的双方可以同时发送和接收信息。

3. 信号
	1. 基带信号<br>
		来自信源的信号。指没有经过调制的数字信号或模拟信号。
		1. 曼彻斯特编码信号<br>
			每个原始信号码元固定用两个连续极性相反的脉冲来表示,1码用正、负电平表示(也就是先正后负,对应的编码为10)，0码用负、正电平表示(也就是先负后正,对应的编码为01)。其关键特点就是在每个码元的1/2码元位置必须进行极性跳变
			1. 优点: **每一位的中间有一跳变，位中间的跳变既作时钟信号，又作数据信号，所以具有自同步能力和良好的抗干扰性能。**
			2. 缺点: 每一个码元都被调成两个电平，所以编码效率50%
			
		2. 差分曼彻斯特编码<br>
			编码规则：对于二进制信号中的第一个码元与曼彻斯特的转换方式一样，都是在1/2码元时进行电平极性跳变,即把0码转换成01码,把1码转换成10码；后面的信号码就根据以下两条规则跳变：如果本码为1,开始处的电平不跳变；如果本码为0,开始处的电平必须跳变。<br>
			**相比曼彻斯特编码，可以解决当极性反转时引起的译码错误。**
			1. 优点: 收发双方可以根据编码自带的时钟信号来保持同步，无需专门传递同步信号的线路
			2. 缺点: 每一个码元都被调成两个电平，所以编码效率50%

		3. 不归零码<br>
			信号电平由0、1表示，并且在表示完一个码元后，电压不需回到0	。常见有CMI码
			
		4. 例子<br>
			![](https://github.com/yinfork/Android-Interview/blob/master/res/network/manchester_encoding.jpg?raw=true)
			
	2. 宽带信号<br>
		指将基带信号调制后形成频分复用模拟信号。

4. 物理层之下的传输媒体
	1. 双绞线
	2. 同轴电缆
	3. 光缆		

5. 信道复用技术<br>
	通信线路的架设费用较高，需要尽可能地充分使用每个信道的容量，尽可能不重复建设通信线路
	1. 频分复用FDM<br>
		ADSL技术采用频分复用技术把普通的电话线分成了电话、上行和下行三个相对独立的信道，从而避免了相互之间的干扰。用户可以边打电话边上网，不用担心上网速率和通话质量下降的情况。
	2. 时分复用TDM
	3. 码分多址CDMA：每个用户可以在同样的时间使用同样的频带进行通信。

6. 调制器和解调器
	1. 调制器：基带数字信号波形转为模拟信号的波形
	2. 解调器：将经过调制器变换的模拟信号恢复成原来的数字信号

7. 常用单位
	1. 带宽（bandwidth）<br>
		在计算机网络中，表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。常用来表示网络的通信线路所能传送数据的能力。单位是“比特每秒”，记为b/s。
	2. 码元（code）<br>
		在使用时间域（或简称为时域）的波形来表示数字信号时，代表不同离散数值的基本波形。
	3. 信噪比（signal-to-noise ratio ）<br>
		指信号的平均功率和噪声的平均功率之比，记为S/N。信噪比（dB）=10*log10（S/N）
	4. 比特率（bit rate ）
		单位时间（每秒）内传送的比特数。

8. 定理
	1. 奈氏准则<br>
		理想低通信道最高码元传输速率 = 2W Baud（即每赫兹理想低通信道最高码元传输速率每秒2个码元）		
	2. 香农定理<br>
		信道的极限传输速率C = Wlog2(1+S/N)，W为带宽，S为平均功率，N为高斯噪声功率，S/N也称为信噪比
	3. 采样定理<br>	
		只要采样频率不低于电话信号最高频率的2倍，就可以从采样脉冲信号无失真地恢复出原来的电话信号。

9. 参考
	1. 	https://zhuanlan.zhihu.com/p/52248268
	2. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#%E5%85%AB-http%E9%95%BF%E8%BF%9E%E6%8E%A5%E3%80%81%E7%9F%AD%E8%BF%9E%E6%8E%A5
	3. https://github.com/it-interview/EasyJob/blob/master/Network/network.md
	4. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E5%B9%B2%E8%B4%A7%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.md

----

<span id = "network_data_link_layer"></span>
#### 数据链路层 [(TOP)](#home)
1. 概述<br>
	1. 作用<br>
		**在原始的、有差错的物理传输线路的基础上，采取差错检测，差错控制和流量控制等方法，将有差错的物理线路改进成逻辑上的无差错的数据链路，以便向他的上一层网络层提供透明可靠的数据传输服务。**
	
	2. 细节<br>
		在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。 控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。
	3. 数据单位<br>
		数据链路层传输的协议数据单元是帧
	
	4. 为什么要封装成帧<br>
		物理层数据是一位一位单独传输的，传输效率低，而且容易出现数据传输差错，通过数据链路层把数据进行封装成以帧为单位进行传输，可以提高传输效率，而且还能做数据传输差错控制。
	
	5. 与物理层的区别<br>
		物理层和数据链路层的本质作用都是用来构建网络通信、访问通道，但它们所建立的通信通道是不一样的。在物理层上构建的是物理链路，在数据链路层上构建的是逻辑链路或者数据链路。

	6. 数据帧头部会放源MAC地址和目标MAC地址

2. 链路层基本需要实现的功能
	1. 数据链路管理<br>
		**TODO**
	
	2. 封装成帧<br>
		在网络层传输的包（packet，又称分组），放在数据链路层中传输的是“帧”(frame)。数据包到达数据链路层后加上数据链路层的协议头和协议尾就构成了一个数据帧。在每个帧的前部加上一个帧头部，在帧的结尾处加上一个帧尾部，把网络层的数据包作为帧的数据部分，就构成了一个完整帧。帧头和帧尾就是作为帧的起始和结束标志，也就是帧边界
		<br>
		<img src="https://github.com/yinfork/Android-Interview/blob/master/res/network/data_link_frame.png?raw=true" width = "300px" height = "300px" />
		
		<br><br>
		**帧边界**<br>
		帧的数据部分的上限 <= MTU（最大传输单元）<br>
		MTU指帧中数据部分但不包括帧头和帧尾部分，同时，帧还有最小大小限制，如果封装的 IP 包小于最小帧要求时，就要用一些特殊字符进行填充
		
	3. 透明传输<br>
		指要使在数据链路层上所传输的数据在内容、格式及编码上都没有限制，也就是要使一些本来用于特殊用途的控制字符也能像正常的数据一样传输
		
	4. 差错控制
		1. 概念<br>
			为保证数据的正确传输。要实现差错控制须具备两种能力：
			1. 发现差错的能力
			2. 纠正错误的能力；
		2. 差错检测	<br>
			在数据链路层检测数据传输错误的方法-~般是通过对差错编码进行校验来实现，常见的校验方法有：
			1. 奇偶校验码(PPC)<br>
				1. 思想<br>
					原信息代码的最后添加一位用于奇校验或偶校验的代码,根据被传输的一组二进制代码的数位中“1”的个数是奇数或偶数来进行校验的。采用“1”的奇数个校验的方法称为奇校验，反之称为偶校验
				2. 缺点<br>
					奇偶校验方法只可以用来检査单个码元错误,检错能力较差,所以一般只用于本身误码率较低的环境,如用于以太局域网中、用于磁盘的数据存储中等
				
			2. 循环冗余校验(CRC)
				1. 思想<br>
					先在要发送的帧后面附加一个数，这个附加的数不是随意的，它要使加上这个数后所生成的新帧能与发送端和接收端共同选定的某个特定数整除（采用模2除法）。<br>
					到达接收端后，再把接收到的新帧除以（同样采用模2除法）这个选定的除数。因为在发送端发送数据帧之前就已附加了一个数，做了去余处理（也就已经能整除了），所以结果应该没有余数。如果有余数，则表明该帧在传输过程中出现了差错。
				2. 模2除法<br>
					与算术除法类似、但它既不向上位借位，也不比较除数和被除数的相同位数值的大小，只以相同位数进行相除。
				3. CRC校验码的计算示例<br>
					**TODO**<br>
					可参考：https://zhuanlan.zhihu.com/p/52665008
		3. 差错纠正<br>	
			**TODO**<br>
			可参考：https://zhuanlan.zhihu.com/p/52665008


3. 协议
	1. 点对点协议PPP<br>
		PPP是数据链路层使用最多的一种协议，它的特点是：简单，只检测差错而不去纠正差错，不使用序号，也不进行流量控制，可同时支持多种网络层协议。如我们在使用 Modem 进行拨号连接时就需要用到它，路由器设备间的 Serial 口之间的连接也要封装这个协议
	2. PPPoE是为宽带上网的主机使用的链路层协议

4. 网络设备
	1. 计算机网卡
	2. 网桥
	3. 二层交换机（注意是二层）

5. 参考
	1. https://zhuanlan.zhihu.com/p/52665008
	2. https://github.com/it-interview/EasyJob/blob/master/Network/network.md
	3. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#%E5%85%AB-http%E9%95%BF%E8%BF%9E%E6%8E%A5%E3%80%81%E7%9F%AD%E8%BF%9E%E6%8E%A5 

----

<span id = "network_network_layer"></span>
#### 网络层 [(TOP)](#home)
1. 概述
	1. 作用<br>
		**计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。**
	
	2. 数据单位<br>
		分组和包。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。

2. IP地址
	1. IP地址的表示
		IPv4的情况，IP地址是一个32位的二进制标识符<br>
		三种IP地址的表示：
		1. 分类IP地址
		2. 划分子网
		3. 构造超网

3. 分类的IP地址<br>
	1. 介绍<br>
 		分类的IP地址是指将固定的IP地址划分为若干个固定的类，每一类都有两个固定长度的字段组成。<br>
		IP地址::={<网络号>,<主机号>} 
		1. 其中第一个字段是网络号，标志着主机（路由器）所连接的网络，网络号是全网唯一的；
		2. 第二个字段是主机号，标志网络号所指的网络内的主机（路由器）。
	
	2. 分类<br>
		分类的IP地址根据网络号所占比特位个数不同，分为5类：A类、B类、C类、D类、E类，其中A、B、C类为单播地址，D类为多播地址，E类为保留地址。<br>
 		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_ip_type.png?raw=true)
		1. A类IP地址
			1. 网络号<br>
				A类地址的网络号字段占1个字节，但前面的1位(0)已经固定，只剩下7位可以进行分配，即可指派的网络号是126个(即2^7-2)。<br>
				减去2是因为：
				1. 网络号字段为全0的IP地址是个保留地址，意思是“本网络”；
				2. 网络号为127(即01111111)保留作为本地软件环回测试(loopback test)本主机的进程之间的通信只用。
			
			2. 主机号<br>
			 	A类地址的主机号占3个字节，因此每一个A类网络中的最大主机数是2^24-2，即16777214。<br>
				减去2是因为：
				1. **全0的主机号字段表示该IP地址是“本主机”所连接到的单个网络地址(例如，一主机的IP地址为5.6.7.8，则该主机所在的网络地址就是5.0.0.0)。**
				2. **全1的主机号字段表示该IP地址是“所有的”，即该网络上的所有主机。**
			 
		2. B类IP地址
			1. 网络号<br>
				B类地址的网络号字段占2个字节，但前面的2位(1 0)已经固定，只剩下14位可以进行分配。因为128.0.0.0是保留地址，所以指派的B类最小网络地址是128.1.0.0，可指派的网络数是2^14-1，即16383。
				
			2. 主机号<br>
				B类地址的主机号占2个字节，每一个网络上的最大主机数是2^16-2，即65534，这里需要减2是因为要扣除全0和全1的主机号。 
			
		3. C类IP地址	
			1. 网络号<br>
				C类地址的网络号字段占3个字节，但前面的3位(11 0)已经固定，只剩下21位可以进行分配。因为192.0.0.0是不指派的，而可以指派的C类最小网络地址是192.0.1.0。因此C类地址可指派的网络数是2^21-1，即2097151
			2. 主机号<br>
				C类地址的每一个网络上的最大主机数是2^8-2，即254，这里需要减2是因为要扣除全0和全1的主机号。
	
	3. IP地址分类的原因<br>
		各种网络差异很大，有些网络拥有很多主机，有些网络拥有的主机相对较少，把IP地址划分为A类、B类、C类能更好的满足需求，当某个单位申请了一个IP地址时，实际是获得了同样网络号的一个IP地址块，其中的各台主机号则由单位自行分配。	
		
	4. IP地址分的缺点<br>
		1. IP地址空间的利用率有时候很低，地址浪费大<br>
			A类拥有超过65535台主机；B类拥有介于255~65535台主机；C类拥有小于255台主机<br>
			只有两、三台主机的网络，也至少要一个C类IP地址;A、B类浪费更严重，少有达上万台主机的大型IP网络。
		2. 路由表太大，影响网络性能<br>	
 			路由器需要能够从路由表中找出怎样到达其他网络的下一跳地址，而一个物理网络对应一个网络号，如果网络越多，则路由表越大，路由器的存储空间就需要越大，查找也更耗时。<br>
 			解决方法：使用构造超网，则能减少网络数，提升性能。
		3. 不够灵活<br>	
 			企业有很多部门，每个部门可能需要各自独立的网络，这怎么办呢？再申请网络？可是人数又不多，怎么办呢？<br>
 			解决方法：划分子网，而且便于管理。
 			
3. 划分子网 
	1. 概念<br>
		划分子网是指将IP类网划分为若干个子网。一般是从网络的主机号用若干位作为子网号（当然用来分配的主机号就相应减少），于是二级网络便成了三级网络。<br>
	<img src="https://github.com/yinfork/Android-Interview/blob/master/res/network/network_subnet.png?raw=true" width = "255px" height = "63px" /> <br>
 		划分子网后，发送到子网某台主机的IP数据报，仍是根据IP数据报的目的网络号找到连接到路由器，然后路由器根据IP数据报的目的网络号和子网号找到子网，再把IP数据报交付主机。<br>
 		划分子网后，ip地址的网络号是不变的，因此在局域网外部看来，这里仍然只存在一个网络，即网络号所代表的那个网络；但在网络内部却是另外一个景象，因为我们每个子网的子网号是不同的，当用化分子网后的ip地址与子网掩码做'与'运算时，每个子网将得到不同的子网地址，从而实现了对网络的划分。
	
	2. 子网掩码<br>
		1. 概念<br>
	 		子网掩码是一个应用于TCP/IP网络的32位二进制值，它可以屏蔽掉ip地址中的一部分，从而分离出ip地址中的网络部分与主机部分，基于子网掩码，管理员可以将网络进一步划分为若干子网。
		2. 为什么需要子网掩码<br>
	 		IP数据报中是没有子网的相关信息，这时可以通过将本机的子网掩码与接受方主机的ip地址进行'与'运算，即可得到目标主机所在的网络号，又由于每台主机在配置TCP/IP协议时都设置了一个本机ip地址与子网掩码，所以可以知道本机所在的网络号。<br>
	 		通过比较这两个网络号，就可以知道接受方主机是否在本网络上。如果网络号相同，表明接受方在本网络上，那么可以通过相关的协议把数据包直接发送到目标主机；如果网络号不同，表明目标主机在远程网络上，那么数据包将会发送给本网络上的路由器，由路由器将数据包发送到其他网络，直至到达目的地。
	 		
		3. 子网掩码得到网络/主机地址的计算	
			1. 将ip地址与子网掩码转换成二进制；
			2. 将二进制形式的ip地址与子网掩码做'与'运算，将答案化为十进制便得到网络地址；
			3. 将二进制形式的子网掩码取'反'；
			4. 将取'反'后的子网掩码与ip地址做'与'运算，将答案化为十进制便得到主机地址。
			5. 例子<br>
				假设有一个IP 地址：192.168.0.1<br>
				子网掩码为：255.255.255.0<br>
				化为二进制为：IP地址11000000.10101000.00000000.00000001<br>
				子网掩码11111111.11111111.11111111.00000000<br>
				将两者做'与'运算得：11000000.10101000.00000000.00000000<br>
				将其化为十进制得：192.168.0.0<br>
				这便是上面ip的网络地址，主机地址以此类推，得到主机地址是1
				
		4. 子网掩码的分类
			1. 缺省子网掩码<br>
				即未划分子网，对应的网络号的位都置1，主机号都置0。
				1. A类网络缺省子网掩码：255.0.0.0
				2. B类网络缺省子网掩码：255.255.0.0
				3. C类网络缺省子网掩码：255.255.255.0
			2. 自定义子网掩码<br>	
	 			将主机号分为两个部分：子网号、子网主机号。
				1. 未做子网划分的ip地址：网络号＋主机号
				2. 做子网划分后的ip地址：网络号＋子网号＋子网主机号

	3. 划分子网的利弊
		1. 好处
			1. 划分子网一个最为重要意义就在于减少广播所带来的负面影响，提高性能的整体性能。因为广播数据包只能在同一网段中传输，网络规模小了，网络中用户数少了，当然所占用的资源也就少了。
			2. 节省了IP地址资源
			3. 由于不同子网之间是不能直接通信的（但可通过路由器或网关进行），在网络安全形势不容乐观的今天，网络越小，安全性就相对越高，因为入侵的途经小了。
			4. 便于维护 
		2. 缺点
			1. 可连接的主机数减少。
			2. 至于各子网间不能直接通信，可以说是既是它的利，又是它的害，会带来诸多的不便。
	
4. 无分类编址CIDR（构造超网）
	1. 出现背景<br>
		对于A、B类地址，很少有这么大规模的公司能够使用，而C类地址所容纳的主机数又相对太少。所以有类别的IP地址并不利于有效地分配有限的地址空间，不适用于网络规划。<br>
		在这种情况下，人们开始致力于下一代因特网协议——IPv6的研究。由于现在IPv6的协议并不完善和成熟，需要长期的试验验证，因此，IPv4到IPv6的完全过渡将是一个比较长的过程，在过渡期间我们仍然需要在IPv4上实现网络间的互连。所以引入了变长子网掩码（VLSM）和无类域间路由（CIDR）等机制，作为目前过渡时期提高IPv4地址空间使用效率的短期解决方案起到了很大的作用。
	
	2. 解决的问题
		1. 大小比较适中的B类IP地址的严重匮乏。
		2. 因特网主干网上的路由表中的项目数急剧增长。
		3. Ipv4地址迟早被分配完，到时候再无IP地址可以分配。
	
	3. 实现原理
		1. 消除传统的A，B，C地址和划分子网的概念，更有效的分配IPv4的地址空间，CIDR使IP地址又回到无分类的两级编码。记法：IP地址::={<<网络前缀>，<<主机号>}。CIDR还使用“斜线记法”即在IP地址后面加上“/”然后写网络前缀所占的位数（192.198.80.72/22）
		2. CIDR把网络前缀都相同的连续IP地址组成一个“CIDR地址块”，即强化路由聚合（构成超网）。一个CIDR地址块中有很多地址，所以在路由表中就利用CIDR地址块来查找目的网络。这种地址的聚合常称为路由聚合，它是的路由表中的一个项目可以表示原来传统分类地址的很多个理由。路由聚合也称为构成超网。路由聚合有利于减少路由器之间的路由选择信息的交换，从而提高了整个因特网的性能。
	
	4. 与划分子网的区别
		1. 子网是把网络拆分，而超网则是把网络聚合。
		2. 为了更方便地进行路由选择，CIDR使用32位的地址掩码。地址掩码是一串1和一串0组成，而1的个数就是网络前缀的长度。虽然CIDR不使用子网了，但由于目前仍有一些网络还使用子网划分和子网掩码，因此CIDR使用的地址掩码也可以继续称为子网掩码。斜线记法中，斜线后面的数字就是地址掩码中1的个数。 
	
	5. 构成超网的几个规则
		1. 构成超网的地址块数必须是2的N（N＝1、2、3……)次幂。
		2. 构成超网的地址块（超块）必须是连续的地址块。
		3. 超块的第一个地址的第三字节必须能够被块数均匀的分开（开始地址必须能被地址数N整除）

6. 交换机、网关与路由器<br>
	1. 交换机<br>
		1. 原理<br>
			交换机拥有一条很高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背部总线上，控制电路收到数据包以后，处理端口会查找内存中的MAC地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口，目的MAC若不存在，广播到所有的端口，接收端口回应后交换机会“学习”新的MAC地址，并把它添加入内部MAC地址表中。
		2. 大多数交换机工作于OSI参考模型的第二层，即数据链路层。
		3. 只是对数据转发和过滤，不会重新打包数据
	
	2. 	网关
		1. 网关在网络层以上实现网络互连
		2. 与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求 
		3. **TODO:RIP协议、端口映射**
		4. TODO：了解网关和默认网关、网段
		
	3. 默认网关<br>
		默认网关事实上不是一个产品而是一个网络层的概念，PC本身不具备路由寻址能力，所以PC要把所有的IP包发送到一个默认的中转地址上面进行转发，也就是默认网关。<br>
		在主机的网络属性配置中，除了有自身的逻辑IP地址，还有默认的网关地址。默认网关地址就是用来不同网络之间的主机进行通信的一扇门。只有通过默认网关，主机的数据包才能够被发送到不同网络的主机中。<br>
		这个默认网关可以在路由器上，可以在三层交换机上，可以在防火墙上，可以在服务器上，所以和物理的设备无关。
		
	4. 路由器<br>
		提供了路由与转送两种重要机制
		1. 可以决定数据包从来源端到目的端所经过的路由路径（host到host之间的传输路径），这个过程称为路由；
		2. 将路由器输入端的数据包移送至适当的路由器输出端(在路由器内部进行)，这称为转送	
	5. 区别<br>
		**TODO**<br>
		简单介绍:<br>
		要使网络A和网络B能够通信，只使用网关将这两个网络连接即可，因为只有两个网络，不需要决定网络间最短路径。
		如果需要连接多个网络，为了保证网络的可靠性，网络结构需要设计为全网状或部分网状，这样，为了网络间的通信，需要网关和路由器两种设备。

7. 路由转发基本流程<br>
	![](https://github.com/yinfork/Android-Interview/blob/master/res/network/ip_route_demo.png?raw=true)<br>
	假设主机甲要跟主机乙进行通信，那么主机甲如何才能够找到主机乙的位置？
	1. 当用户在主机甲上输入PING 172.168.80.8之后，主机甲中有一个网际控制报文协议ICMP。这个协议将创建一个回应请求数据包，在它的数据域中只包含有字母。
	2. 网际控制报文协议会将这个有效负荷(即刚创建的数据包)交给网际协议IP。<br>
		这个网际协议也会创建一个数据包。在这个网际协议IP创建的数据包中，在这个包中包括主机甲的IP地址、目的地主机已的IP地址以及值为01h的协议字段。当数据包到达主机乙时，这些内容就是告诉对方，应该将这个有效负荷交给网际控制报文协议来处理。
	3. IP协议会判断目的IP地址是属于远程网络，还是在本地网络。<br>
		由于根据IP地址规划规则，主机甲与主机乙属于不同的网络。此时，刚才网际协议IP所创建的数据包将会被发送到默认的网关中去。<br>
		在主机甲的网络属性配置中，除了有自身的逻辑IP地址，还有默认的网关地址。网关地址就是用来不同网络之间的主机进行通信的一扇门。只有通过网关，主机甲的数据包才能够被发送到不同网络的主机乙中。
	4. 确认路由器相应接口的MAC地址<br>
		假设主机甲(IP地址为172.168.60.6)的默认网关被配置为172.168.60.1。若主机甲的数据包要发送到这个默认网关上，则就必须知道其对应的路由器接口的物理地址，即MAC地址。得到目标IP的MAC地址后，数据包将会被释放并传递到数据链路层并生成帧。其中目的方的硬件地址也将同数据包一起下传到数据链路层。<br>
		当主机甲要把数据包发送给特定的网关时，必须要知道这个网关所对应的MAC地址。以下是简要的ARP过程：
		1. 主机甲首先会检查自己的ARP缓存，查看一个默认网关的IP地址是否已经解析为对应接口的硬件地址。
		2. 如果不存在，则将ARP请求帧广播到本地网络上的所有主机。
		3. 本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配
		4. 如果匹配，则目标主机将包含其MAC地址的ARP回复消息直接发送回主机甲。
		5. 当主机甲收到从目标主机发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。		
	
	5. 生成帧<br>
		当这个数据包和目的方的硬件地址被传递给数据链路层之后，一个数据帧即将产生，一旦完成帧的封装，则这个帧将会被交付到物理层。在这个帧中，主要包括:
		1. 目的MAC地址<br>
			这里指的目的地址并不是主机乙的地址，而是里主机甲最近的默认网关地址。在第一次通信时，主机甲并不知道主机乙的MAC地址。
		2. 源MAC地址(主机甲的MAC地址)
		3. 以太网类型字段<br>
			这个以太网类型字段主要用来描述的是交付这个数据包到数据链路层的网络层协议
		4. 数据包
		5. 帧校验序列<br>
			装载循环冗余校验计算值的区域
	6. 发送和接受帧
		1. 在主机甲所在的冲突域中的每台网络设备都将接收这些位并重新合并成数据帧。（冲突域是在同一个网络上两个设备同时进行传输则会产生冲突；冲突域就是连接在同一导线上的所有工作站的集合）
		2. 接收完毕后，他们会运行CRC过程并核对保存在帧校验序列字段中的内容。
		3. 如果这两个值不匹配的话，则这个帧将会被丢弃。如果两个值相同，则网络设备会接收这个帧，并核查目的方的硬件地址，检查他们是否也匹配。
		4. 如果目的方的硬件地址也是匹配的，那么路由器将会查看这个帧的以太网类型字段，以了解在网络层上采用了什么协议
		5. 然后路由器就会抽出帧中的数据包，把其余部分内容丢弃。然后把抽出来的数据包传送给以太网类型字段中列出的上层协议，如网际协议IP等等。
	7. 判断路由表项目。<br>
		网际协议IP会接收这个数据包，并检查目的IP地址。在这个案例中，由于数据包中的目的地址与接收路由器所配置的任何地址都不相匹配。此时，路由器就会在自己的路由表（**在路由表中，对每一条路由最主要的是以下两个信息：目的网络地址，下一跳地址**）中，查看目的IP的网络地址。在这个案例中，由于路由器同时连接着172.16.80.0的网络。所以在这个路由器的路由表中，有相关的纪录。若没有记录的话，则这个数据包会被直接丢弃。若路由器丢弃数据包的话，则会发送一个“目标地址不可达”的错误信息给主机甲。
	8. 路由器转发数据包<br>
		如果路由器的确在他的路由表中找到了相应网络的记录，则数据包就会被转发到输出接口。在本例中，就是主机乙所连接的接口。路由器会将这个数据包交换到对应接口的缓冲区内。
	9. 确认主机乙的MAC地址<br>
		路由器对应接口的缓冲区需要了解目的方主机的硬件地址。参考第四步，通过ARP缓存或者ARP请求获取主机乙的MAC地址。<br>
		路由器知道目的主机乙的MAC地址之后，就会把数据包连同目的方的MAC地址传递到下一层的数据链路中。
	10. 路由器会重复上面的第五步操作，生成数据帧。并传送到物理层，以一次一位的方式再发送到物理媒体上。在网络中进行传输。
	11. 主机乙会接收数据并响应ICMP协议<br>
		1. 主机乙会接收到这个数据帧并运行CRC过程
		2. 如果运算结果与帧校验序列中字段的内容相同，则这个帧中目的方的MAC地址将会被读取
		3. 主机乙会判断这个MAC地址是否跟自己的MAC地址相同
		4. 若相同的话，则会抽取其中的数据包，并根据以太网字段类型中指定的协议，把数据包传递给相应的协议处理
		5. 由于这个是ICMP协议的数据包，所以交给ICMP协议处理。ICMP协议会应答这个请求，同时把这个数据包丢弃并迅速生成一个新的有效负荷来作为回应应答。
		6. 主机乙会利用同样的过程把数据包以及目的MAC地址(路由器对应接口的物理地址)传递到下一层，让其生成帧。<br>
			在数据帧上，会带有目的MAC地址、源MAC地址、数据包、以太网字段类型、帧校验序列字段等内容发送到下一层。然后再一位位的传送到物理媒体
	12. 路由器再重复第六步到第十步的过程，把数据包从一个接口交换传递到另一个接口中。然后主机甲就收到一个回应信息，表示到主机乙的道路是通的。		
	13. 小结
		1. 第一到五步主要都是在主机甲上完成。这五个步骤执行完毕之后，IP路由选择过过程的前期工作就算完成了。
		2. 第六到十步是网际协议IP路由选择的步骤。可以看出路由器的作用主要就是进行数据交换。把其收到的数据包根据一定的规则转发到另一个可达的接口上。<br>
			路由器就好像是一个十字路口，各个数据包都根据自己所需要到达的目的地，现在合适的出口。	
		
8. 各种路由
	1. 静态路由<br>
		指由网络管理员手工配置的路由信息。当网络的拓扑结构或链路的状态发生变化时，网络管理员需要手工去修改路由表中相关的静态路由信息。静态路由信息在缺省情况下是私有的，不会传递给其他的路由器，但也可以设置使之成为共享的。<br>
		静态路由一般适用于比较简单的网络环境，在这样的环境中，网络管理员易于清楚地了解网络的拓扑结构，便于设置正确的路由信息。
	2. 动态路由<br>
		是指路由器能够自动地建立自己的路由表，并且能够根据实际实际情况的变化适时地进行调整。动态路由机制的运作依赖路由器的两个基本功能：对路由表的维护；路由器之间适时的路由信息交换。
	3. 特定主机路由<br>
		即对特定的目的主机指明的一个路由。这种路由叫做特定主机路由。<br>
		采用特定主机路由的好处：
		1. 可使网络管理人员能够更方便地控制网络和测试网络，同时也可在需要考虑某种安全问题时采用这种特定主机路由。
		2. 在对网络的连接或路由表进行排错时，指明到某一主机的特定路由就十分有用。
	
	4. 默认路由<br>
		默认路由是一种特殊的静态路由，指的是当路由表中与包的目的地址之间没有匹配的表项时路由器能够做出的选择。<br>
		如果没有默认路由，那么目的地址在路由表中没有匹配表项的包将被丢弃。<br>
		默认路由在某些时候非常有效，当存在末梢网络时，默认路由会大大简化路由器的配置，减轻管理员的工作负担，提高网络性能。<br>
		主机里的默认路由通常被称作默认网关，默认网关通常会是一个有过滤功能的设备，如防火墙和代理服务器。
	
9. 分类IP路由分组转发算法
	1. 从数据报的首部提取目的主机的IP地址D，得出目的网络地址为N。
	2. 若N就是与此路由器直接相连的某个网络地址，则进行直接交付，不需要再经过其他的路由器，直接把数据报交付给目的主机（这里包括把目的主机地址D转换为具体的硬件地址，把数据报封装为MAC帧，再发送此帧）；否则就要执行(3)进行间接交付。
	3. 若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器，否则执行(4)。
	4. 若路由表中有到达网络N的路由，则把数据报传送给路由表中所指明的下一跳路由器，否则执行(5)。
	5. 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的下一跳路由器，否则执行(6)。
	6. 报告转发分组出错。
		
10. 划分子网下的分组转发<br>
	**使用子网划分后，路由表必须包含以下三项内容：目的网络地址、子网掩码和下一跳地址。**<br>
在划分子网的情况下，路由转发分组的算法如下(和没划分子网的情况比较下，大体的流程是不变的)：
	1. 从收到的数据报的首部提取目的IP地址D。
	2. 先判断是否为直接交付。对路由器直接相连的网络逐个进行检查：用各网络的子网掩码和D逐位相“与”（AND操作），看结果是否和相应的网络地址匹配。若匹配，则把分组进行直接交付（还需把D转换成物理地址，把数据报封装成帧发送出去），转发任务结束。否则就是间接交付，执行（3）。
	3. 若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行（4）。
	4. 对路由表中的每一行（目的网络地址、子网掩码、下一跳地址），用其中的子网掩码和D逐位相“与”（AND），其结果为N。若N与该行的目的网络地址匹配，则把数据报传送给该行指明的下一跳路由器；否则，执行（5）。
	5. 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则，执行（6）。
	6. 报告转发分组出错。

11. 构造超网下的分组转发<br>
	在使用使CIDR时，由于采用了网络前缀这种记法，IP地址由网络前缀和主机号这两个部分组成，因此在路由表中的项目也要有相应的改变。这时，**路由表中的每个项目由“网络前缀”和“下一跳地址”组成。**<br>
	但是在查找路由表时可能会得到不止一个匹配结果。这个时候我们应当从匹配结果中**选择具有最长网络前缀的路由，这叫作最长前缀匹配**。即选择两个匹配结果中地址更具体的一个。<br>
	路由转发分组的算法和分类IP、划分子网的路由转发时差不多，只是第二步改成利用网络前缀来判断是否为直接交付

12. 配套的四个协议
	1. ARP（Address Resolution Protocol）地址解析协议<br>
		1. 作用：IP地址 -> MAC地址
		2. 过程：<br>
			当主机A的IP地址为192.168.1.1，MAC地址为0A-11-22-33-44-01；<br>
			主机B的IP地址为192.168.1.2，MAC地址为0A-11-22-33-44-02；<br>
			以下为工作流程：
			1. 根据主机A上的路由表内容，IP确定用于访问主机B的转发IP地址是192.168.1.2。然后A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址。
			2. 如果主机A在ARP缓存中没有找到映射，它将询问192.168.1.2的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。
			3. 主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。
			4. 主机B将包含其MAC地址的ARP回复消息直接发送回主机A。
			5. 当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。
		
	2. RARP（Reverse Address Resolution Protocol）逆地址解析协议（已经被淘汰）<br>
		MAC地址 -> IP地址	
	
	3. ICMP（Internet Control Message Protocol）因特网控制报文协议 <br>
		用于TCP/IP网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，令管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。比如常见的Ping命令
	
	4. IGMP（Internet Group Management Protocol）因特网组管理协议<br>
		用于管理网路协议多播组成员的一种通信协议。IP主机和相邻的路由器利用IGMP来创建多播组的组成员。


13. IP数据报<br>
	![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_ip_data.png?raw=true)

14. 其他常用协议和工具
	TODO:路由选择协议、OSPF（开放式最短路径优先）、BGP（边界网关协议）、DHCP（动态主机设置协议）、NAT（地址转换协议）<br>
	参考：https://github.com/hadyang/interview/blob/master/basic/net/base_protocol.md
	<br><br>
	工具：<br>
	Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具

15. 参考
	1. https://www.jianshu.com/p/155d4bfcdac1
	2. https://www.jianshu.com/p/1165bfc708c0
	3. https://www.jianshu.com/p/8c8c1d1f2344
	4. https://zhuanlan.zhihu.com/p/37820182
	5. https://zhuanlan.zhihu.com/p/26098552
	6. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#%E5%85%AB-http%E9%95%BF%E8%BF%9E%E6%8E%A5%E3%80%81%E7%9F%AD%E8%BF%9E%E6%8E%A5
	7. https://github.com/hadyang/interview/blob/master/basic/net/base_protocol.md
		
----

<span id = "network_transport_layer"></span>
#### 运输层 [(TOP)](#home)
1. 作用<br>
	**运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务**。网络层的IP协议可以将数据包送到目的主机，但并未交付到具体的进程，而运输层则提供了应用进程之间的逻辑通信，同时还负责对收到的报文进行差错检查。

2. 端口<br>
	协议端口号（简称端口）是运输层的概念，当网络层将数据包送达主机时必须能够知道其希望与主机的哪一个进程进行交互，而端口号即标识了具体的某一个进程
	1. 服务端使用的端口号（0~49151）<br>
		服务端的端口号也分为两类：系统端口号和登记端口号。系统端口号范围是0~1023，是被IANA指派到一些特定应用的端口号，例如FTP是21，HTTP是80等。而登记端口号范围1024~49151，必须按照IANA规定程序登记方可使用。
	2. 客户端使用的端口号（49152~65535）<br>
		这些端口号是客户端进程运行时动态选择临时使用，和服务端通信时，服务端将响应报文发回至客户端相应的临时端口号，通信结束后这个端口号可能就已经被别的客户端进程使用了。

3. 运输层主要使用以下两种协议
	1. 传输控制协议 TCP（Transmisson Control Protocol）--提供面向连接的，可靠的数据传输服务。
	2. 用户数据协议 UDP（User Datagram Protocol）--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。
	3. 常见应用层协议对应的运输层协议图<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/common_protocol.png?raw=true)

4. UDP协议
	1. 简介<br>
		**UDP只在IP层的数据报上添加了很少的功能，包括端口信息和差错检测，UDP首部只有8个字节（TCP头部有20字节）。<br>
		UDP是传输层协议，并不提供超时重传，出错重传等功能，也就是说其是不可靠的协议。<br>**
		UDP协议主要用来支持那些需要在计算机之间传输数据的网络应用。包括网络视频会议系统在内的众多的C/S模式的网络应用都需要使用UDP协议。UDP协议直接位于IP（网际协议）协议的顶层。
	2. 特点
		1. 无连接，发送数据之前不需要建立连接。开销减少和发送之前的时间延迟较短。
		2. 尽最大努力交付（可以采取一定策略实现可靠传输）。
		3. 面向报文，UDP对应用程序交付的报文，添加UDP首部后直接交给IP层。不合并，不拆分。
		4. 没有拥塞控制，网络拥塞不会使源主机发送率降低。
		5. UDP支持一对一，一对多，多对一的交互通信。
		6. UDP首部开销较小，8字节（TCP为20字节、IP为20字节）。
	3. UDP首部的格式<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/udp_head.png?raw=true)
		<br>
		首部由8个字节四个部分组成，每个部分由2个字节。
		1. 源端口：在需要交互方回信的时候选用，不需要回信使用0。
		2. 目的端口：在终点交付报文的时候必须使用。
		3. 长度：udp用户数据报的长度，最小为8。
		4. 检验和：检测udp数据报在传输中是否有错误，有错就将其丢弃。（在计算检验和的时候，要在udp用户数据报之前添加12个字节的伪首部，伪首部既不下传递也不向上递交，作用仅为计算检验和）
		5. 伪首部
			1. 伪首部是不占地址空间的，在实际传输中不存在这样的字段。只是在使用的时候把它拿出来设置一下
			2. 设置伪首部只是为了计算检验和。其目的是让UDP两次检查数据是否已经正确到达目的地。如何两次检验？<br>
				1. 第一次，通过伪首部的IP地址检验，UDP可以确认该数据报是不是发送给本机IP地址的；
				2. 第二次，通过伪首部的协议字段检验，UDP可以确认IP有没有把不应该传给UDP而应该传给别的高层的数据报传给了UDP。

5. TCP协议
	1. 简介<br>
		TCP（Transmission Control Protocol）传输控制协议是一种面向连接的、可靠的、基于字节流的传输层（Transport layer）通信协议，在1981年由IETF的RFC 793正式提出。
TCP的主要功能是在互联网中为提供可靠的、面向连接的进程间通信服务。
	2. 特点
		1. 面向连接的传输;
		2. 端到端的通信;
		3. 高可靠性，确保传输数据的正确性，不出现丢失或乱序;
		4. 全双工方式传输;
		5. 采用字节流方式，即以字节为单位传输字节序列;
		6. 紧急数据传送功能;	
	3. TCP首部的格式<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/tcp_head.png?raw=true)<br>
		1. 源端口和目的端口（Source Port和Destination Port）：分别占用2个字节，用于区别主机中的不同进程，而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接。
		2. 序号seq（Sequence Number）：占4个字节，用来标识从TCP发端向TCP收端发送的数据字节流（tcp传输的每一个字节都按顺序编号），主要用来解决网络报乱序的问题。
			1. 如果含有同步化旗标（SYN），则此为最初的序列号；第一个数据比特的序列码为本序列号加一。
			2. 如果没有同步化旗标（SYN），则此为第一个数据比特的序列码。
		3. 确认号ack（Acknowledgment Number）：占4个字节，确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志为1时该确认序列号的字段才有效。主要用来解决不丢包的问题（确认序号减去上次收到的序号等于本段收到的报文的长度）。
		4. 数据偏移（Offset）：占4个bit，指出tcp报文段的数据起始处距离tcp报文段的起始有多远，这个字段实际指出Ttcp报文段的首部长度。需要这个值是因为任选字段的长度是可变的，它用来表示首部中32bit（4字节）字的数目，因此最多能表示15个32bit的的字，即4*15=60个字节的首部长度），因此TCP最多有60字节的首部。然而，没有任选字段，正常的长度是20字节。
		5. 保留（3比特长）—须置0
		6. 标志符（9比特长）<br>
			1. NS：ECN-nonce。
			2. CWR：Congestion Window Reduced。
			3. ECE：ECN-Echo有两种意思，取决于SYN标志的值。
			4. URG：为1表示高优先级数据包，紧急指针字段有效。告诉系统这个报文段中有紧急数据，应当尽快传输。
			5. ACK：为1表示TCP头部的确认号字段有效，反之为0
			6. PSH：为1表示是带有PUSH标志的数据，指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。
			7. RST：表示连接复位请求，为1表示出现严重差错。可能需要重现创建TCP连接。还可以用于拒绝非法的报文段和拒绝连接请求。
			8. SYN：为1表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步。
				1. 创建连接时，SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1；
				2. 被用作端口扫描<br>
					这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手。
			9. FIN：为1表示发送方没有数据要传输了，要求释放连接。
		7. 窗口：占2个字节，表示从确认号开始，本报文的接受方可以接收的字节数，即接收窗口大小。用于流量控制。
		8. 检验和：占2个字节。—对整个的TCP报文段，包括TCP头部和TCP数据，以16位字进行计算所得。这是一个强制性的字段。
		9. 紧急指针：占2个字节。本报文段中的紧急数据的最后一个字节的序号。
		10. 选项和填充：40字节。每个选项的开始是1字节的kind字段，说明选项的类型。填充是为了使TCP首部为4byte的整数倍。
			1. kind=0：选项表结束（1字节）
			2. kind=1：无操作（1字节）用于选项字段之间的字边界对齐。
			3. kind=2：最大报文段长度（4字节，Maximum Segment Size，MSS）通常在创建连接而设置SYN标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将MSS设置为（MTU-40）字节，携带TCP报文段的IP数据报的长度就不会超过MTU，从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。
			4. kind=3：窗口扩大因子（4字节，wscale），取值0-14。用来把TCP的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。这是因为现在的TCP接收数据缓冲区（接收窗口）的长度通常大于65535字节。
			5. kind=4：sackOK—发送端支持并同意使用SACK选项。<br>
				SACK含义：用于数据重传中的“选择确认”（selective acknowledgment，SACK）选项。RFC 2018对此定义为允许接收方确认它成功收到的分组的不连续的块，以及基础TCP确认的成功收到最后连续字节序号。
			6. kind=5：SACK实际工作的选项。
			7. kind=8：时间戳（10字节，TCP Timestamps Option，TSopt）
				1. 发送端的时间戳（Timestamp Value field，TSval，4字节）
				2. 时间戳回显应答（Timestamp Echo Reply field，TSecr，4字节）
	
	
	4. 常见名词
		1. 最大分段大小（MSS）<br>
			最大分段大小 (MSS)是在单个分段中TCP愿意接受的数据的字节数最大值。MSS应当足够小以避免IP分片，它会导致丢包或过多的重传。在TCP连接创建时，双端在SYN报文中用MSS选项宣布各自的MSS，这是从双端各自直接相连的数据链路层的最大传输单元(MTU)的尺寸减去固定的IP首部和TCP首部长度。
		2. 重传超时时间(RTO，Retransmission TimeOut)<br>
			TODO：RTO是怎么设定的
		3. 连接往返时间(RTT)
	
	5. TCP通过以下方式来提供可靠性
		1. 序列号<br>
			序列号是指按照顺序给发送数据包中的每一个字节都标识上号码编号。<br>
			作用：
			1. 应答
			2. 接收方对数据包进行排序，把有序数据传送给应用层
			3. 去掉重复的数据
			
		2. 确认应答处理<br>
			接收端主机根据接收数据TCP包首部中的序列号和数据长度，来将自己下一步应该接收的序列号作为确认应答返送回去，从而实现可靠传输

		3. 自动重传<br>
			自动重传请求是OSI模型中**数据链路层**和**传输层**的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送，实现可靠传输。<br>
			1. TCP使用两套独立的机制来完成重传<br>
				1. 基于时间的超时重传<br>
					TCP协议要求在发送端每发送一个报文段，就启动一个定时器并等待确认信息；接收端成功接收新数据后返回确认信息。若在定时器超时前数据未能被确认，TCP就认为报文段中的数据已丢失或损坏，需要对报文段中的数据重新组织和重传。
				2. 基于重复累计确认信息的快速重传<br>
					1. 优点<br>
						快速重传机制基于接收端的反馈信息来引发重传，而非基于计时器超时重传。与超时重传相比，快速重传能更加及时有效地修复丢包情况。
					2. 实现原理<br>
	       			快速重传机制要求当接收到失序报文段时，TCP需要立即生成确认信息（重复ACK），并且失序情况表明在后续数据到达前出现了丢包，发送端的工作即为尽快填补丢包带来的数据段空缺。
					3. 与拥塞控制的关系<br>
						根据重复ACK推断的丢包通常与网络拥塞有关，因此快速重传也会触发拥塞控制机制。
					4. 示例图<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/fast_resend.png?raw=true)<br>
			
			2. 重复累积确认信息下如何重传数据
				1. 回退N重传<br>
					接收点丢弃从第一个没有收到的数据包开始的所有数据包。发送点收到NACK后，从NACK中指明的数据包开始重新发送。
				2. 带选择确认的重传<br>
					1. 介绍<br>
						发送点连续发送数据包但对每个数据包都设有个一个计时器。当在一定时间内没有收到某个数据包的ACK时，发送点只重新发送那个没有ACK的数据包。（使用SACK选项）
					2. SACK
						1. 介绍<br>
							普通 TCP（即未提供 SACK 特性）应答是严格累积的：对 N 的应答意味着字节 N 和所有之前的字节都已经收到。SACK 要解决的问题普通累积式应答的 “全有或全无” 性质。
						2. 例子<br>
							包 2（假设从 0 到 9 的序列）是在传送过程中惟一丢失的包，接收方也只能对包 1 发出一个普通的 ACK，因为这是连续接收到的包中的最后一个。另一方面，SACK 接收方可以发出包 1 的 ACK 和包 3 到包 9 的 SACK 选项。这种附加信息可以帮助发送方确定丢失的包最少，只需重新传送很少的数据。如果没有这种附加信息，它需要重新传送大量的数据，这样会降低传送速率，从而适应高丢包率的网络。
						3. SACK数量<br>
							每个包中的最多包含 4 个 SACK 选项（假设使用了时间戳选项，最多则只有3个）
				
			3. 对应的实现协议<br>
				ARQ包括停止等待ARQ协议和连续ARQ协议
				1. 停止等待ARQ协议
					1. 原理<br>
						1. 发送点对接收点发送数据包，然后等待接收点回复ACK并且开始计时。
						2. 在等待过程中，发送点停止发送新的数据包。
						3. 当数据包没有成功被接收点接收时候，接收点不会发送ACK.这样发送点在等待一定时间后，重新发送数据包。<br>
							没成功接收到的情况：
							1. 所发送的数据丢失
							2. 确认消息丢失
							3. 确认消息延时
						4. 反复以上步骤直到收到从接收点发送的ACK.
					2. 示意图<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/stop_and_wait_arq.png?raw=true) 
					3. 缺点<br>
						TCP是以一个段为单位进行数据的传输的，每发送一个段，就会等待对端主机的针对这个段的确认应答信号ACK。较长的等待时间导致低的数据传输速度。
				2. 连续ARQ协议
					1. 原理<br>
						1. 为了克服停止并等待ARQ协议长时间等待ACK的缺点。这个协议会连续发送一组数据包，然后再等待这些数据包的ACK.
						2. 接受方采用累积确认的方式：接收方不必每收到一个消息，就发送一个确认。而是在收到几条消息后，对按序到达的最后一条消息发送确认。表示这个消息之前的所有消息全部收到。
					2. 两种重传的方式
						1. 回退N重传(Go-Back-N)<br>
							接收点丢弃从第一个没有收到的数据包开始的所有数据包。发送点收到NACK后，从NACK中指明的数据包开始重新发送。
						2. 选择重传(Selective Repeat)<br>
							发送点连续发送数据包但对每个数据包都设有个一个计时器。当在一定时间内没有收到某个数据包的ACK时，发送点只重新发送那个没有ACK的数据包。
					3. 示意图<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/continuous_arq.png?raw=true) 

		4. 重复处理<br>
			TCP 的接收端会丢弃重复的数据。
			
		5. 校验和<br>
			1. 计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。 
			2. 发送方：在发送数据之前计算检验和，并进行校验和的填充。 
			3. 接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。
		6. 连接管理<br>
			1. 三次握手<br>
				建立一个TCP连接需要三次握手
				1. 示意图<br>
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/tcp_connect.png?raw=true) 

				2. 流程
					1. 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
					2. 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
					3. 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端
				3. 三次握手的含义<br>
					三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的，缺一不可。
					1. 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常
					2. 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常
					3. 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常
				4. 为什么要三次握手<br>
					为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。<br>
				具体例子——“已失效的连接请求报文段”的产生在这样一种情况下：<br>
				client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。<br>
				例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”
			
			2. 四次挥手<br>
				断开一个TCP连接需要四次挥手
				1. 示意图
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/tcp_disconnect.png?raw=true) 
				
				2. 流程
					1. 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
					2. 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号
					3. 服务器-关闭与客户端的连接，发送一个FIN给客户端
					4. 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1
				
				3. 为什么要四次挥手<br>
					任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。<br>
					举个例子：<br>
					A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。
				
		7. 使用滑动窗口协议实现流量控制<br>
			1. 滑动窗口的作用<br>
				1. 实现面向流的可靠性保证
					1. 发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界。
					2. 接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。

				2. 实现流量控制<br>
					1. 让发送端主机根据接收端主机的实际接收能力来控制自己发送的数据量<br>
						应用根据自身的处理能力变化，通过本端TCP接收窗口大小控制来对对对端的发送窗口流量限制。发送端主机会根据自己的实际情况发送数据，而接收端也会跟据自己的实际情况接收数据。
					2. 提高传输速度<br>
						TCP是以一个段为单位进行数据的传输的，每发送一个段，就会等待对端主机的针对这个段的确认应答信号ACK，但这样的传输方式的缺点也很明显，就是：当数据包的往返时间越长，通信性能越低。
						而使用滑动窗口后，确认应答包不再以每个段为单位进行确认了，而是以更大的单位进行确认，转发时间将会被大幅度的缩短。也就是说，发送端主机在发送了一个段之后，没必要一直等待对端主机的确认应答信号，而是继续发送。
			2. 窗口<br>
				TCP首部中，专门有一个字段用来通知“窗口大小”。接收端主机向发送端主机通知自己所能够接收数据的大小，于是发送端主机就会发送不超过这个限度的数据，这个值是由接收端主机决定的。TCP滑动窗口分为接受窗口，发送窗口：
				1. 发送窗口<br> 					发送窗口：无需等待接收端主机的确认应答信号而可以持续发送的数据的最大值<br>
					发送方任何时候在其发送缓存内的数据都可以分为4类，“已经发送并得到对端ACK的”，“已经发送但还未收到对端ACK的”，“未发送但对端允许发送的”，“未发送且对端不允许发送”。<br>
					其中“已经发送但还未收到对端ACK的”和“未发送但对端允许发送的”这两部分数据称之为发送窗口。<br>
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/sliding_window_classify.png?raw=true)
					
				2. 接收窗口<br>
					对于TCP的接收方，在某一时刻在它的接收缓存内存在3种。“已接收”，“未接收准备接收”，“未接收并未准备接收”（由于ACK直接由TCP协议栈回复，默认无应用延迟，不存在“已接收未回复ACK”）。其中“未接收准备接收”称之为接收窗口。
				3. 发送窗口与接收窗口关系<br>	
					TCP是双工的协议，会话的双方都可以同时接收、发送数据。TCP会话的双方都各自维护一个“发送窗口”和一个“接收窗口”。其中各自的“接收窗口”大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。各自的“发送窗口”则要求取决于对端通告的“接收窗口”，要求相同。
		
			3. 实现
				1. 建立连接后，接收端会告诉发送端，自己的"接收窗口"大小，发送端接收到接收端的"接收窗口"大小，就会变成发送端自己的"发送窗口"大小。因为TCP是双工的，同样发送端也会告诉接收端自己的接收窗口的大小。
				2. 当发送方收到接收方新的ACK，对于发送窗口中后续字节的确认时，窗口滑动。发送端窗口的第一个字节序号一定是ACK中期望收到的下一个字节序号<br>
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/sliding_window_demo.png?raw=true)
				3. 接收端主机的缓冲区一旦面临数据溢出，就会主动减小窗口的大小再次发送给发送端主机，从而可以控制数据发送量。也就是说，发送端主机会根据接收端主机的指示，对发送的数据量进行控制，这也就形成了一条完整的TCP流量控制。
			
			4. 当窗口大小为0时的探测处理<br>
				当接收方宣布接收窗口的值为0，发送方停止进一步发送数据，开始了“保持定时器”（persist timer），**以避免因随后的修改接收窗口的数据包丢失使连接的双侧进入死锁**，发送方无法发出数据直至收到接收方修改窗口的指示。当“保持定时器”到期时，TCP发送方尝试恢复发送一个小的ZWP包（Zero Window Probe），期待接收方回复一个带着新的接收窗口大小的确认包。一般ZWP包会设置成3次，如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。
					
			5. 示例<br>
				![](https://github.com/yinfork/Android-Interview/blob/master/res/network/sliding_window.png?raw=true)<br>
				client端和server端已经三次握手建立TCP连接，总窗口大小是TCP建立连接时候确定的。黑色框代表client和server总的窗口大小，红色框代表实际可用的窗口大小。初始化的时候默认client和server总窗口和可用端口分别都是360。另外，假设Client总共只发送360bytes数据，所以总窗口大小不会往前移动。
				1. client 发送140bytes到server端，Seq=1，Length=140；可用窗口大小往前移动，变成260bytes，总窗口大小不变，依然是360。这中间的120是已发送，等待确认;
				2. server端收到140bytes，放入buffer中，但是应用程序很繁忙，只取出100个字节。这时候可用窗口大小: 260(360-100)。接着server端要给client发确认，Ack=141，Window=260。黑框左边缘向前移动，表示140字节已经确认收到，但是应用程序太慢，处理很忙导致我现在只能处理260bytes(回顾下上面server端收到数据要做的两件事);
				3. client收到来自server端的ack回应，首先总窗口左边缘向前移动，表示第一步的140bytes server已经收到，剩下260数据。接着被告知server的可接收窗口是260，client就调整自己的发送窗口是260，表示一次发数据不能超过260;client发送180bytes，可用窗口变成80(260-180)，等待确认发送的180bytes;
				4. server收到180bytes，放入buffer中，应用程序依然很繁忙，这次一个字节都不处理。此时可用窗口大小:80(260-180)，然后发180 ack给client，并告知窗口大小80;
				5. client收到ack，确认之前发送的180已经到达，剩余数据还有80字节。被告知server端接收窗口大小是80，调整自己的发送窗口大小为80
				6. client发送80bytes，可用窗口变成0(80-80)，等待确认发送的80bytes;
				7. server收到180bytes，放入buffer中，应用程序依然很繁忙，一个字节都不处理。此时可用窗口大小:80(80-80)，然后发80 ack给client，并告知窗口大小0;
				8. client收到ack，确认之前发送的80已经到达。被告知server端接收窗口大小是0，调整自己的发送窗口大小为0，此时无论client是否还有数据要发送，都不能再发了。	
		
		8. 拥塞控制
			1. 问题背景<br>
				计算机网络都处在一个共享的环境中，如果网络上的延时突然增加，那么TCP对这个事做出的应对只有重传数据，但是重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。
			2. 解决思路<br>
				TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了
			3. 运作过程<br>
				1. TCP会为每条连接维护一个“拥塞窗口”来限制可能在端对端间传输的未确认分组总数量。
				2. TCP在一个连接初始化或超时后使用一种“慢启动”机制来增加拥塞窗口的大小。它的起始值一般为最大分段大小（MSS）的两倍，虽然名为“慢启动”，初始值也相当低，但其增长极快：当每个分段得到确认时，拥塞窗口会增加一个MSS，使得在每次往返时间（RTT）内拥塞窗口能高效地双倍增长。
				3. 当拥塞窗口超过慢启动阈值时，算法就会进入一个名为“拥塞避免”的阶段。在拥塞避免阶段，只要未收到重复确认，拥塞窗口则在每次往返时间内线性增加一个MSS大小。
			
			4. 拥塞控制的方法
				1. 拥塞窗口<br>
					拥塞窗口是任何时刻内确定能被发送出去的字节数的控制因素之一，是阻止发送方至接收方之间的链路变得拥塞的手段。他是由发送方维护，通过估计链路的拥塞程度计算出来的，与由接收方维护的接收窗口大小并不冲突。
				2. 慢启动<br>
					1. 慢启动的介绍<br>
						慢启动初始启动时设置拥塞窗口值为1、2、4或10个MSS。拥塞窗口在每接收到一个确认包时增加，每个RTT内成倍增加，当然实际上并不完全是指数增长，因为接收方会延迟发送确认，通常是每接收两个分段则发送一次确认包。发送速率随着慢启动的进行而增加，直到遇到出现丢失、达到慢启动阈值、或者接收方的接收窗口进行限制。
					2. 慢启动的缺点<br>
						1. 慢启动假设分段的未确认是由于网络拥塞造成的，虽然大部分网络的确如此，但也有其他原因，例如一些链路质量差的网络，会导致分段包丢失。在一些网络环境，例如无线网络，慢启动效率并不好。
						2. **慢启动对于一些短暂的连接性能并不好，一些较旧的网页浏览器会创建大量连续的短暂链接，通过快速开启和关闭链接来请求获得文件，这使得大多数链接处于慢启动模式，导致网页响应时间差**。所以现在新的网页浏览器，会通过向特殊的服务器，开启一条链接来请求获得全部的文件，而避免频繁新建大量短暂链接。
				
				3. 快重传<br>
					1. 普通的重传机制: TCP 的可靠传输的原理就是超时重传机制。配合上面的慢开始和拥塞避免使用就是发送发发送完数据后设置一个定时器，如果在定时器时间内没有收到对接收方发来的确认的话就去执行上述的乘法减小过程并重新开始慢开始算法。
					2. 快重传则是允许发送方再连续收到 3 个重复的确认后就可以开始执行乘法减小过程而不必再等待所设置的重传计时器到时。<br>
						但是快重传有两个实现算法，主要区别是是否进入慢启动：
						1. Tahoe(废弃)：如果收到三次重复确认，Tahoe算法则进入快速重传，将慢启动阈值改为当前拥塞窗口的一半，将拥塞窗口降为1个MSS，并重新进入慢启动阶段。
						2. Reno：如果收到三次重复确认，Reno算法则进入快速重传，只将拥塞窗口减半来跳过慢启动阶段，将慢启动阈值设为当前新的拥塞窗口值，进入一个称为“快速恢复”的新设计阶段。
					
				4. 快恢复<br>	
					快恢复算法是与快重传算法配合使用的一个算法(连续接收到三个重复的确认)。快恢复是快重传Reno算法新引入的一个阶段<br>
					使用了快恢复算法后与原来不同的一点是当发现网络出现拥塞并执行了乘法减小过程后，并不是设置cwnd=1并重新开始执行慢开始算法，而是让 cwnd =乘法减小后的ssthresh并开始执行拥塞避免算法。
					
				5. 拥塞避免<br>
					不能任由慢开始算法中的 cwnd 指数增长，所以我们引入一个慢开始门限（ssthresh）的阈值来控制 cwnd 的增长。
					1. 规则
						1. cwnd < ssthresh , 使用慢开始算法
						2. cwnd = ssthresh , 使用慢开始算法或拥塞避免算法都可以
						3. cwnd > ssthresh , 使用拥塞避免算法呢
					2. ssthresh的设置<br>
						TCP/IP 中规定无论是在慢开始阶段还是在拥塞避免阶段，只要发现网络中出现拥塞（没有按时收到确认），就要把ssthresh设置为此时发送窗口的一半大小（不能小于2）。
					3. 普通的拥塞避免过程<br>
						每个传输轮次后将 cwnd 的大小加一（加法增大），如果发现出现网络拥塞的话就按照上面的方法重新设置ssthresh的大小（乘法减小）并从cwnd=1开始重新执行慢开始算法。<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/congest.png?raw=true)
					4. 使用了快重传和快恢复的拥塞避免过程<br>						每个传输轮次后将 cwnd 的大小加一（加法增大），如果发现出现网络拥塞的话就按照上面的方法重新设置ssthresh的大小（乘法减小），然后并不是设置cwnd=1并重新开始执行慢开始算法，而是让 cwnd =乘法减小后的ssthresh并开始执行拥塞避免算法。<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/congest_fast.png?raw=true)
				
			5. 拥塞控制与流量控制的区别<br>
				1. 拥塞控制就是防止过多的数据注入到网络中，这样可以防止网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。流量控制往往指点对点通信量的控制，是个端到端的问题。
				2. 流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。
		9. 应用数据被分割成 TCP 认为最适合发送的数据块<br>
			对应的概念：最大分段大小 (MSS)

6. TCP、UDP 协议的区别
	1. 示意图<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/tcp_udp_diff.png?raw=true)
	2. 简介
		1. UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等
		2. TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。


7. 参考
	1. https://www.jianshu.com/p/ca2289a15b06 
	2. https://www.jianshu.com/p/97e5d7e73ba0
	3. https://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6
	4. https://www.jianshu.com/p/8afbbdd4af48
	5. https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE
	6. https://www.zhihu.com/question/32255109
	7. https://zh.wikipedia.org/wiki/%E8%87%AA%E5%8A%A8%E9%87%8D%E4%BC%A0%E8%AF%B7%E6%B1%82
	8. https://blog.csdn.net/qq_37653144/article/details/82743760
	9. https://blog.csdn.net/cmm0401/article/details/77878998

----

<span id = "network_application_layer"></span>
#### 应用层 [(TOP)](#home)
1. 定义<br>
	通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。

2. 常见协议<br>
	![](https://github.com/yinfork/Android-Interview/blob/master/res/network/common_application_protocol.png?raw=true)

3. HTTP协议详解
	1. HTTP协议特点
		1. HTTP构建于TCP/IP协议之上，默认端口号是80。
		2. HTTP是无连接<br>
			无连接的含义是 限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接
		3. HTTP是无状态<br>
			无状态是指 协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。
		
		4. 无连接无状态的优点和缺点
			1. 优点<br>
				优点在于解放了服务器，每一次请求“点到为止”不会造成不必要连接占用
			2. 缺点<br>
				为了解决HTTP无状态的缺点，两种用于保持 HTTP 连接状态的技术就应运而生了，一个是 Cookie，而另一个则是 Session。Cookie在客户端记录状态，比如登录状态。Session在服务器记录状态。<br>
				所以缺点在于每次请求会传输大量重复的内容信息。
	
	2. HTTP请求报文<br>
		一个HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据4个部分组成<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/http_request_detail.png?raw=true)
	
		1. 请求行<br>
			请求行分为三个部分：请求方法、请求地址和协议版本
			1. 请求方法<br>
				HTTP/1.1 定义的请求方法有8种：GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE。<br>
				最常的两种GET和POST，如果是RESTful接口的话一般会用到GET、POST、DELETE、PUT。
				1. GET<br>
					请求指定的页面信息，并返回实体主体。<br>
					**GET可提交的数据量受到URL长度的限制，HTTP协议规范没有对URL长度进行限制。网上常说的2kb限制，这个限制是特定的浏览器及服务器对它的限制**
				2. POST<br>
					向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。<br>
					理论上讲，POST是没有大小限制的，HTTP协议规范也没有进行大小限制，出于安全考虑，服务器软件在实现时会做一定限制
				3. PUT<br>
					从客户端向服务器传送的数据取代指定的文档的内容。
				4. DELETE<br>
					请求服务器删除指定的页面。
				
			2. 请求地址<br>
				URL：统一资源定位符，是一种自愿位置的抽象唯一识别方法。<br>
				组成：<协议>：//<主机>：<端口>/<路径><br>
				端口和路径有时可以省略（HTTP默认端口号是80）<br>
				如下例：<br>
				![](https://github.com/yinfork/Android-Interview/blob/master/res/network/http_url.png?raw=true) <br>		
				有时会带参数，比如上图的GET请求
				
			3. 协议版本<br>
				协议版本的格式为：HTTP/主版本号.次版本号，常用的有HTTP/1.0和HTTP/1.1
			
		2. 请求头<br>
			请求头部为请求报文添加了一些附加信息，由“名/值”对组成，每行一对，名和值之间使用冒号分隔。<br>
			**请求头部的最后会有一个空行，表示请求头部结束，接下来为请求数据，这一行非常重要，必不可少。**<br>
			常见的请求头:<br>
			1. User-Agent：产生请求的浏览器类型。
			2. Accept：客户端可识别的响应内容类型列表;
			3. Accept-Language：客户端可接受的自然语言;
			4. Accept-Encoding：客户端可接受的编码压缩格式;
			5. Accept-Charset：可接受的应答的字符集;
			6. Host：请求的主机名，允许多个域名同处一个IP 地址，即虚拟主机;
			7. Connection：连接方式(close 或 keep-alive);
			8. Cookie：存储于客户端扩展字段，向同一域名的服务端发送属于该域的cookie;
			9. Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。
			10. If-Modified-Since：文档的最后改动时间
	
		3. 请求数据<br>
			可选部分，比如GET请求就没有请求数据。
	
		4. 一个POST方式的请求例子
			
			```
			POST 　/index.php　HTTP/1.1 　　 请求行
			Host: localhost
			User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2　　请求头
			Accept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8
			Accept-Language: zh-cn,zh;q=0.5
			Accept-Encoding: gzip, deflate
			Connection: keep-alive
			Referer:http://localhost/
			Content-Length：25
			Content-Type：application/x-www-form-urlencoded
			　　空行
			username=aa&password=1234　　请求数据
			```
	
	3. HTTP响应报文<br>
		HTTP响应报文主要由状态行、响应头部、空行以及响应数据组成。
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/http_response_detail.png?raw=true)
	
		1. 状态行<br>
			由3部分组成，分别为：协议版本，状态码，状态码描述。
			其中协议版本与请求报文一致，状态码描述是对状态码的简单描述<br>
			HTTP的状态码含义<br>
			1. 1**	信息，服务器收到请求，需要请求者继续执行操作
			2. 2**	成功，操作被成功接收并处理
			3. 3**	重定向，需要进一步的操作以完成请求
				1. 301 Moved Permanently。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替
				2. 302 Moved Temporarily。与301类似。但资源只是临时被移动。客户端应继续使用原有URI
				3. 304 Not Modified。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源。
			4. 4**	客户端错误，请求包含语法错误或无法完成请求
				1. 400 Bad Request 由于客户端请求有语法错误，不能被服务器所理解。
				2. 401 Unauthorized 请求未经授权。这个状态代码必须和WWW-Authenticate报头域一起使用
				3. 403 Forbidden 服务器收到请求，但是拒绝提供服务。服务器通常会在响应正文中给出不提供服务的原因
				4. 404 Not Found 请求的资源不存在，例如，输入了错误的URL
			5. 5**	服务器错误，服务器在处理请求的过程中发生了错误
				1. 500 Internal Server Error 服务器发生不可预期的错误，导致无法完成客户端的请求。
				2. 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。
	
		2. 响应头部<br>
			与请求头部类似，为响应报文添加了一些附加信息
			1. Allow	服务器支持哪些请求方法（如GET、POST等）。
			2. Content-Encoding	文档的编码（Encode）方法。
			3. Content-Length	表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。
			4. Content-Type	表示后面的文档属于什么MIME类型。
			5. Date	当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。
			6. Expires	应该在什么时候认为文档已经过期，从而不再缓存它。
			7. Last-Modified	文档的最后改动时间。
			8. Refresh	表示浏览器应该在多少时间之后刷新文档，以秒计。
			9. Server	服务器名字。
			10. Set-Cookie	设置和页面关联的Cookie。
			11. ETag：被请求变量的实体值。ETag是一个可以与Web资源关联的记号（MD5值）。
			12. Cache-Control：这个字段用于指定所有缓存机制在整个请求/响应链中必须服从的指令。
		
		3. 响应数据<br>
			用于存放需要返回给客户端的数据信息。
			
		4. 一个响应报文的实例
			
			```
			HTTP/1.1 200 OK　　状态行
			Date: Sun, 17 Mar 2013 08:12:54 GMT　　响应头部
			Server: Apache/2.2.8 (Win32) PHP/5.2.5
			X-Powered-By: PHP/5.2.5
			Set-Cookie: PHPSESSID=c0huq7pdkmm5gg6osoe3mgjmm3; path=/
			Expires: Thu, 19 Nov 1981 08:52:00 GMT
			Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0
			Pragma: no-cache
			Content-Length: 4393
			Keep-Alive: timeout=5, max=100
			Connection: Keep-Alive
			Content-Type: text/html; charset=utf-8
			　　空行
			
			<html>　　响应数据
			<head>
			<title>HTTP响应示例<title>
			</head>
			<body>
			Hello HTTP!
			</body>
			</html>
			```

	4. 浏览器缓存<br>
		HTTP 协议为了减少不必要的带宽浪费，提出的一种方案。利用响应头Last-Modified与请求头If-Modified-Since都是用来记录页面的最后修改时间，从而做浏览器缓存。<br>
		当客户端访问页面时，服务器会将页面最后修改时间通过 Last-Modified 标识由服务器发往客户端，客户端记录修改时间，再次请求本地存在的cache页面时，客户端会通过 If-Modified-Since 头将先前服务器端发过来的最后修改时间戳发送回去，服务器端通过这个时间戳判断客户端的页面是否是最新的，如果不是最新的，则返回新的内容，如果是最新的，则返回 304。

	5. Cookies 与 Session <br>
		TODO
		
	6. 跨站攻击
		1. 定义<br>
			CSRF（Cross-site request forgery，跨站请求伪造）伪造请求，冒充用户在站内的正常操作，比如爬虫。
		2. 防范的方法
			1. 关键操作只接受POST请求
			2. 验证码
			3. 检测 Referer
			4. Token
				1. Token 要足够随机——只有这样才算不可预测
				2. Token 是一次性的，即每次请求成功后要更新Token——这样可以增加攻击难度，增加预测难度
				3. Token 要注意保密性——敏感操作使用 post，防止 Token 出现在 URL 中
		

	7. HTTP的持久连接
		1. 是否持久连接请求：
			1. 当使用普通模式，即非 Keep-Alive 模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接（HTTP协议为无连接的协议）；
			2. 当使用 Keep-Alive 模式（又称持久连接、连接重用）时，Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接。
		2. Http不同版本下请求
			1. HTTP 1.0<br>
				http 1.0中默认是关闭的，需要在http头加入"Connection: Keep-Alive"，才能启用Keep-Alive；然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中：
Connection: Keep-Alive
			2. HTTP 1.1<br>
				http 1.1中默认启用Keep-Alive，如果加入"Connection: close "，才关闭。
		
		3. 细节
			1. HTTP Keep-Alive 简单说就是保持当前的TCP连接，避免了重新建立连接。
			2. HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开。
			3. HTTP是一个无状态协议，这意味着每个请求都是独立的，Keep-Alive没能改变这个结果。另外，Keep-Alive也不能保证客户端和服务器之间的连接一定是活跃的，在HTTP1.1版本中也如此。唯一能保证的就是当连接被关闭时你能得到一个通知，所以不应该让程序依赖于Keep-Alive的保持连接特性，否则会有意想不到的后果。
			4. 使用长连接之后，客户端、服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length 指示的大小；2. 动态生成的文件没有 Content-Length ，它是分块传输（chunked），这时候就要根据 chunked 编码来判断，chunked 编码的数据在最后有一个空 chunked 块，表明本次传输数据结束。

	8. HTTP的断点续传
		1. 简介
			要实现断点续传的功能，通常都需要客户端记录下当前的下载进度，并在需要续传的时候通知服务端本次需要下载的内容片段。<br>
			HTTP1.1协议中定义了断点续传相关的HTTP头 Range 和 Content-Range 字段。<br>

		2. 一个最简单的断点续传实现大概如下：<br>
			1. 客户端下载一个1024K的文件，已经下载了其中512K
			2. 网络中断，客户端请求续传，因此需要在HTTP头中申明本次需要续传的片段：Range:bytes=512000-，这个头通知服务端从文件的512K位置开始传输文件。
			3. 服务端收到断点续传请求，从文件的512K位置开始传输，并且在HTTP头中增加：Content-Range:bytes 512000-/1024000，并且此时服务端返回的HTTP状态码应该是206，而不是200。

		3. 特殊情况：终端发起续传请求时，URL对应的文件内容在服务端已经发生变化，此时续传的数据肯定是错误的。<br>
			解决方法：显然此时我们需要有一个标识文件唯一性的方法。在RFC2616中也有相应的定义，比如 实现Last-Modified来标识文件的最后修改时间，这样即可判断出续传文件时是否已经发生过改动。同时RFC2616中还定义有一个ETag的头，可以使用ETag头来放置文件的唯一标识，比如文件的MD5值。<br>
			客户端在发起续传请求时应该在HTTP头中申明If-Match 或者 If-Modified-Since 字段，帮助服务端判别文件变化。

	9. HTTP的基本优化<br>
		影响一个 HTTP 网络请求的因素主要有两个：带宽和延迟。
		1. 带宽<br>
			如果说我们还停留在拨号上网的阶段，带宽可能会成为一个比较严重影响请求的问题，但是现在网络基础建设已经使得带宽得到极大的提升，我们不再会担心由带宽而影响网速，那么就只剩下延迟了。

		2. 延迟
			1. 浏览器阻塞（HOL blocking）<br>
				浏览器会因为一些原因阻塞请求。浏览器对于同一个域名，同时只能有 4 个连接（这个根据浏览器内核不同可能会有所差异），超过浏览器最大连接数限制，后续请求就会被阻塞。
			2. DNS 查询（DNS Lookup）<br>
				浏览器需要知道目标服务器的 IP 才能建立连接。将域名解析为 IP 的这个系统就是 DNS。这个通常可以利用DNS缓存结果来达到减少这个时间的目的。
			3. 建立连接（Initial connection）<br>
				HTTP 是基于 TCP 协议的，浏览器最快也要在第三次握手时才能捎带 HTTP 请求报文，达到真正的建立连接，但是这些连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。

	10. HTTP1.0和HTTP1.1的一些区别
		1. 缓存处理<br>
			在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

		2. 带宽优化及网络连接的使用<br>
			HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

		3. 错误通知的管理<br>
			在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

		4. Host头处理<br>
			在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。

		5. 长连接<br>
			HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

4. HTTPS
	1. 简介<br>
		HTTPS能够加密信息，以免敏感信息被第三方获取。所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。<br>
		**HTTPS其实是有两部分组成：HTTP + SSL / TLS，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。**

	2. HTTPS加密，解密，验证的过程<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/https_fun.png?raw=true) <br>
		具体流程:<br>
		1. 客户端发起HTTPS请求<br>
			就是用户在浏览器里输入一个https网址，然后连接到server的443端口。
		
		2. 服务端的配置<br>
			采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl就是个不错的选择，有1年的免费服务)。这套证书其实就是一对公钥和私钥。如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。
		
		3. 传送证书<br>
			这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。
		
		4. 客户端解析证书<br>
			这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值。然后用证书对该随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。
		
		5. 传送加密信息<br>
			这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。
		
		6. 服务段加密信息<br>
			服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密。所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。
		
		7. 传输加密后的信息<br>
			这部分信息是服务段用私钥加密后的信息，可以在客户端被还原
		
		8. 客户端解密信息<br>
			客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。

	3. 中间人攻击<br>
		TODO
	
	4. HTTPS与HTTP的一些区别
		1. HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。
		2. HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。
		3. HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
		4. HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。


5. HTTP 2.0
	1. 目标<br>
		HTTP/2 可以让我们的应用更快、更简单、更稳定<br>
		HTTP/2 的主要目标是通过支持完整的请求与响应复用来减少延迟，通过有效压缩 HTTP 标头字段将协议开销降至最低，同时增加对请求优先级和服务器推送的支持。
		
	2. 新特性
		1. 新的二进制格式（Binary Format）<br>
			HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。
	
		2. 多路复用（MultiPlexing）<br>
			![](https://github.com/yinfork/Android-Interview/blob/master/res/network/http2_MultiPlexing.png?raw=true)<br>
			即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。
			1. http协议的队首阻塞
				1. 队首阻塞<br>
					就是需要排队，队首的事情没有处理完的时候，后面的人都要等着。

				2. http1.0的队首阻塞<br>
					对于同一个tcp连接，所有的http1.0请求放入队列中，只有前一个请求的响应收到了，然后才能发送下一个请求。<br>
					可见，http1.0的队首组塞发生在客户端。

				3. http1.1的队首阻塞<br>
					对于同一个tcp连接，http1.1允许一次发送多个http1.1请求，也就是说，不必等前一个响应收到，就可以发送下一个请求，这样就解决了http1.0的客户端的队首阻塞。但是，http1.1规定，服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到的请求的响应也要先发送。这样造成的问题是，如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送。也会造成队首阻塞。<br>
					可见，http1.1的队首阻塞发生在服务器端。

				4. http2是怎样解决队首阻塞的<br>
					http2无论在客户端还是在服务器端都不需要排队，在同一个tcp连接上，有多个stream，由各个stream发送和接收http请求，各个steam相互独立，互不阻塞。<br>
					只要tcp没有人在用那么就可以发送已经生成的requst或者reponse的数据，在两端都不用等，从而彻底解决了http协议层面的队首阻塞问题。

			2. 多路复用解决的问题
				在 HTTP/1.x 中，如果客户端要想发起多个并行请求以提升性能，则必须使用多个 TCP 连接。 这是 HTTP/1.x 交付模型的直接结果，该模型可以保证每个连接每次只交付一个响应（响应排队）。 更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。
				HTTP/2 中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。从而带来巨大的性能提升，让我们可以：
				1. 并行交错地发送多个请求，请求之间互不影响。
				2. 并行交错地发送多个响应，响应之间互不干扰。
				3. 使用一个连接并行发送多个请求和响应。
				4. 不必再为绕过 HTTP/1.x 限制而做很多工作（请参阅针对 HTTP/1.x 进行优化，例如级联文件、image sprites 和域名分片。
				5. 消除不必要的延迟和提高现有网络容量的利用率，从而减少页面加载时间。

		3. header压缩<br>
			如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。

		4. 服务端推送（server push）<br>
			服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源（图 12-5），而无需客户端明确地请求。
			1. 为什么在浏览器中需要一种此类机制呢？<br>
				一个典型的网络应用包含多种资源，客户端需要检查服务器提供的文档才能逐个找到它们。 那为什么不让服务器提前推送这些资源，从而减少额外的延迟时间呢？ 服务器已经知道客户端下一步要请求什么资源，这时候服务器推送即可派上用场。

	3. 二进制分帧层<br>
		HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。<br>
		HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/http2_frame.png?raw=true)
		
		1. 数据流、消息和帧
			![](https://github.com/yinfork/Android-Interview/blob/master/res/network/http2_connction.png?raw=true)<br>
			新的二进制分帧机制改变了客户端与服务器之间交换数据的方式。 为了说明这个过程，我们需要了解 HTTP/2 的三个概念：
			1. 数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。
			2. 消息：与逻辑请求或响应消息对应的完整的一系列帧。
			3. 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。
		
		2. 数据流、消息和帧之间的关系	
			1. 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。
			2. 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。
			3. 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。
			4. 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。

		3. 总结<br>
			简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 这是 HTTP/2 协议所有其他功能和性能优化的基础。

6. DNS<br>
	1. 介绍<br>
		DNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，DNS就像是一个自动的电话号码簿，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。
	
	2. 特点<br>
		DNS协议运行在UDP协议之上，使用端口号53。
	
	3. 有四种类型的 DNS 服务器
		1. 根 DNS 服务器<br>
			根 DNS 服务器存储了所有顶级域 DNS 服务器的 IP 地址，也就是说你可以通过根服务器找到顶级域服务器。例如：www.baidu.com，根服务器会返回所有维护 com 这个顶级域服务器的 IP 地址。
			
		2. 顶级域 DNS 服务器<br>
			顶级域 DNS 服务器主要负责诸如 com、org、net、edu、gov 等顶级域名。<br>
			任意选择其中一个顶级域服务器，请求该顶级域服务器，该顶级域服务器拿到域名后应当能够做出判断并给出负责当前域的权威服务器地址，以百度为例的话，顶级域服务器将返回所有负责 baidu 这个域的权威服务器地址
		
		3. 权威 DNS 服务器<br>
			任意选择其中一个权威服务器地址，向它继续查询 www.baidu.com 的具体 IP 地址，最终权威服务器会返回给你具体的 IP 地址。
		
		4. 本地 DNS 服务器<br>
			每次通过 DHCP 动态获取 IP 地址的时候，这一点后文会说。其实路由器不仅给你返回了 IP 地址，还会告诉你一个 DNS 服务器地址，这个就是你的本地 DNS 服务器地址，也就是说，你的所有域名解析请求只要告诉它就行了，它会帮你查并返回结果给你的。<br>
			本地 DNS 服务器往往是具有缓存功能的，通常两天内的记录都会被缓存，所以大部分时候你是感觉不到域名解析过程的，因为往往就是从缓存里拿的，非常快。
	
	4. DNS请求过程<br>
		以访问xxx.163.com为例子<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/dns_process.png?raw=true) <br>
		①：主机向负责自己的本地 DNS 发送查询报文，如果本地服务器缓存中有，将直接返回结果<br>
		②：本地DNS服务器发现缓存中没有，于是从内置在内部的根服务器列表中选一个发送查询报文<br>
		③：根服务器解析一下后缀名，告诉本地服务器负责 .com 的所有顶级服务器列表<br>
		④：本地DNS服务器选择一个顶级域服务器继续查询，.com 域服务器拿到域名后继续解析，返回负责 .163.com 域的所有权威服务器列表<br>
		⑥：本地DNS服务器从返回的权威服务器之一再次发送查询报文，最终会从某一个权威服务器上得到具体的 IP 地址，并存入自身缓存<br>
		⑧：向主机返回结果<br>

7. 一次HTTP请求的过程<br>
	TODO: 暂时简单地描述
	
	1. 域名解析：
		1. 先判断浏览器本地dns
		2. 假如没有，再判断系统的hosts文件
		3. 假如没有，最后进行DNS请求
			创建一个 UDP 套接字，运行于端口53，开始DNS解析过程（略）
		4. 得到域名对应的ip地址
		
	2. HTTP请求
		1. 应用层<br>
			组装 HTTP 请求报文，包含：请求行、请求头、空行、请求数据(可无)。紧接着，这个应用层数据报会被推进 TCP 套接字中，等待运输层来收取。
			
		2. 运输层
			1. 运输层收取了报文，并判断与目的主机是否建立了 TCP 连接。
假如没建立连接，那么运输层将不急着发送应用层数据，得先判断与目的主机之间能够正常通讯，也就是需要 三次握手 打招呼。
			2. 一切准备就绪之后，运输层将应用层发过来的数据报又一层封装，添加进 源端口号 和 目的端口号 以及相关差错检验字段。
最后将 TCP 数据报向下传递到网络层。
		
		3. 网络层<br>
			拿到数据报并封装成 IP 数据报，即在原 TCP 报文的前提之上添加 源IP地址 和 目的IP地址 等字段信息。
	
		4. 链路层<br>
			数据链路层拿到 IP 数据报，它需要封装成以太网帧才能在网络中传输，也就是它需要目的主机的 Mac 地址，然而我们只知道目的主机的 IP 地址。<br>
			链路层有一个 ARP 协议，直接或间接的能够根据目的 IP 地址获得使用该 IP 地址的主机 Mac 地址。<br>
			当然，ARP 协议运行的前提是，目的 IP 地址和当前发送方主机处于同一子网络中。如果不然，发送方将目的 Mac 地址填自己网关路由的 Mac 地址，然后通过物理层发送出去。
		5. 数据传输<br>
			网关路由由于具有转发表和路由选择算法，所以它知道目的网络该怎么到达，所以一路转发，最终会发送到目的网络的网关路由上，最后被目的主机接受。

	3. HTTP响应<br>
		相当于HTTP请求的逆过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。从而得到 响应行、响应头、空行、响应数据
	4. 根据情况释放TCP连接
	5. 根据响应行的状态码和响应数据，解析html并渲染
	

10. 参考
	1. https://github.com/hadyang/interview/blob/master/basic/net/http.md
	2. https://github.com/LRH1993/android_interview/blob/master/computer-networks/http.md
	3. https://zh.wikipedia.org/wiki/%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F
	4. https://juejin.im/post/5b10be81518825139e0d8160
	5. https://juejin.im/post/5b16057de51d45069352bca8
	6. https://juejin.im/entry/5981c5df518825359a2b9476
	7. https://www.cnblogs.com/hustdc/p/8487366.html
	8. https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cn



<span id = "network_summary"></span>
#### 总结 [(TOP)](#home)
1. 数据封装入帧的流程<br>
	![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_pop_fun.png?raw=true)


2. 数据入栈和出栈的过程<br>
	TCP/IP协议通信的过程其实就对应着数据入栈与出栈的过程。入栈的过程，数据发送方每层不断地封装首部与尾部，添加一些传输的信息，确保能传输到目的地。出栈的过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。<br>
![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_data_fun.png?raw=true)

3. 参考
	1. https://github.com/LRH1993/android_interview/blob/master/computer-networks/tcpip.md

