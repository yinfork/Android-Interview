## 计算机网络
<span id = "home"></span>
#### 目录
1. [协议体系模型](#network_arch)
2. [物理层](#network_physical_layer)
3. [数据链路层](#network_data_link_layer)
4. [网络层](#network_network_layer)
5. [运输层](#network_transport_layer)
6. [应用层](#network_application_layer)

----

<span id = "network_arch"></span>
#### 协议体系模型 [(TOP)](#home)
![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_arch.png?raw=true)

----

<span id = "network_physical_layer"></span>
#### 物理层 [(TOP)](#home)
1. 概述
	1. 作用<br>
		**物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。**
	
	2. 细节<br>
		使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。<br>
	
	3. 数据单位<br>
		在物理层上所传送的数据单位是比特。

2. 传输方向的工作方式
	1. 单工：只能有一个方向的通信而没有反方向的交互。
	2. 半双工：通信的双方都可以发送信息，但不能双方同时发送(当然也就不能同时接收)。
	3. 全双工：通信的双方可以同时发送和接收信息。

3. 信号
	1. 基带信号<br>
		来自信源的信号。指没有经过调制的数字信号或模拟信号。
		1. 曼彻斯特编码信号<br>
			每个原始信号码元固定用两个连续极性相反的脉冲来表示,1码用正、负电平表示(也就是先正后负,对应的编码为10)，0码用负、正电平表示(也就是先负后正,对应的编码为01)。其关键特点就是在每个码元的1/2码元位置必须进行极性跳变
			1. 优点: **每一位的中间有一跳变，位中间的跳变既作时钟信号，又作数据信号，所以具有自同步能力和良好的抗干扰性能。**
			2. 缺点: 每一个码元都被调成两个电平，所以编码效率50%
			
		2. 差分曼彻斯特编码<br>
			编码规则：对于二进制信号中的第一个码元与曼彻斯特的转换方式一样，都是在1/2码元时进行电平极性跳变,即把0码转换成01码,把1码转换成10码；后面的信号码就根据以下两条规则跳变：如果本码为1,开始处的电平不跳变；如果本码为0,开始处的电平必须跳变。<br>
			**相比曼彻斯特编码，可以解决当极性反转时引起的译码错误。**
			1. 优点: 收发双方可以根据编码自带的时钟信号来保持同步，无需专门传递同步信号的线路
			2. 缺点: 每一个码元都被调成两个电平，所以编码效率50%

		3. 不归零码<br>
			信号电平由0、1表示，并且在表示完一个码元后，电压不需回到0	。常见有CMI码
			
		4. 例子<br>
			![](https://github.com/yinfork/Android-Interview/blob/master/res/network/manchester_encoding.jpg?raw=true)
			
	2. 宽带信号<br>
		指将基带信号调制后形成频分复用模拟信号。

4. 物理层之下的传输媒体
	1. 双绞线
	2. 同轴电缆
	3. 光缆		

5. 信道复用技术<br>
	通信线路的架设费用较高，需要尽可能地充分使用每个信道的容量，尽可能不重复建设通信线路
	1. 频分复用FDM<br>
		ADSL技术采用频分复用技术把普通的电话线分成了电话、上行和下行三个相对独立的信道，从而避免了相互之间的干扰。用户可以边打电话边上网，不用担心上网速率和通话质量下降的情况。
	2. 时分复用TDM
	3. 码分多址CDMA：每个用户可以在同样的时间使用同样的频带进行通信。

6. 调制器和解调器
	1. 调制器：基带数字信号波形转为模拟信号的波形
	2. 解调器：将经过调制器变换的模拟信号恢复成原来的数字信号

7. 常用单位
	1. 带宽（bandwidth）<br>
		在计算机网络中，表示在单位时间内从网络中的某一点到另一点所能通过的“最高数据率”。常用来表示网络的通信线路所能传送数据的能力。单位是“比特每秒”，记为b/s。
	2. 码元（code）<br>
		在使用时间域（或简称为时域）的波形来表示数字信号时，代表不同离散数值的基本波形。
	3. 信噪比（signal-to-noise ratio ）<br>
		指信号的平均功率和噪声的平均功率之比，记为S/N。信噪比（dB）=10*log10（S/N）
	4. 比特率（bit rate ）
		单位时间（每秒）内传送的比特数。

8. 定理
	1. 奈氏准则<br>
		理想低通信道最高码元传输速率 = 2W Baud（即每赫兹理想低通信道最高码元传输速率每秒2个码元）		
	2. 香农定理<br>
		信道的极限传输速率C = Wlog2(1+S/N)，W为带宽，S为平均功率，N为高斯噪声功率，S/N也称为信噪比
	3. 采样定理<br>	
		只要采样频率不低于电话信号最高频率的2倍，就可以从采样脉冲信号无失真地恢复出原来的电话信号。

9. 参考
	1. 	https://zhuanlan.zhihu.com/p/52248268
	2. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#%E5%85%AB-http%E9%95%BF%E8%BF%9E%E6%8E%A5%E3%80%81%E7%9F%AD%E8%BF%9E%E6%8E%A5
	3. https://github.com/it-interview/EasyJob/blob/master/Network/network.md
	4. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E5%B9%B2%E8%B4%A7%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.md

----

<span id = "network_data_link_layer"></span>
#### 数据链路层 [(TOP)](#home)
1. 概述<br>
	1. 作用<br>
		**在原始的、有差错的物理传输线路的基础上，采取差错检测，差错控制和流量控制等方法，将有差错的物理线路改进成逻辑上的无差错的数据链路，以便向他的上一层网络层提供透明可靠的数据传输服务。**
	
	2. 细节<br>
		在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。 控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。
	3. 数据单位<br>
		数据链路层传输的协议数据单元是帧
	
	4. 为什么要封装成帧<br>
		物理层数据是一位一位单独传输的，传输效率低，而且容易出现数据传输差错，通过数据链路层把数据进行封装成以帧为单位进行传输，可以提高传输效率，而且还能做数据传输差错控制。
	
	5. 与物理层的区别<br>
		物理层和数据链路层的本质作用都是用来构建网络通信、访问通道，但它们所建立的通信通道是不一样的。在物理层上构建的是物理链路，在数据链路层上构建的是逻辑链路或者数据链路。

	6. 数据帧头部会放源MAC地址和目标MAC地址

2. 链路层基本需要实现的功能
	1. 数据链路管理<br>
		**TODO**
	
	2. 封装成帧<br>
		在网络层传输的包（packet，又称分组），放在数据链路层中传输的是“帧”(frame)。数据包到达数据链路层后加上数据链路层的协议头和协议尾就构成了一个数据帧。在每个帧的前部加上一个帧头部，在帧的结尾处加上一个帧尾部，把网络层的数据包作为帧的数据部分，就构成了一个完整帧。帧头和帧尾就是作为帧的起始和结束标志，也就是帧边界
		<br>
		<img src="https://github.com/yinfork/Android-Interview/blob/master/res/network/data_link_frame.png?raw=true" width = "300px" height = "300px" />
		
		<br><br>
		**帧边界**<br>
		帧的数据部分的上限 <= MTU（最大传输单元）<br>
		MTU指帧中数据部分但不包括帧头和帧尾部分，同时，帧还有最小大小限制，如果封装的 IP 包小于最小帧要求时，就要用一些特殊字符进行填充
		
	3. 透明传输<br>
		指要使在数据链路层上所传输的数据在内容、格式及编码上都没有限制，也就是要使一些本来用于特殊用途的控制字符也能像正常的数据一样传输
		
	4. 差错控制
		1. 概念<br>
			为保证数据的正确传输。要实现差错控制须具备两种能力：
			1. 发现差错的能力
			2. 纠正错误的能力；
		2. 差错检测	<br>
			在数据链路层检测数据传输错误的方法-~般是通过对差错编码进行校验来实现，常见的校验方法有：
			1. 奇偶校验码(PPC)<br>
				1. 思想<br>
					原信息代码的最后添加一位用于奇校验或偶校验的代码,根据被传输的一组二进制代码的数位中“1”的个数是奇数或偶数来进行校验的。采用“1”的奇数个校验的方法称为奇校验，反之称为偶校验
				2. 缺点<br>
					奇偶校验方法只可以用来检査单个码元错误,检错能力较差,所以一般只用于本身误码率较低的环境,如用于以太局域网中、用于磁盘的数据存储中等
				
			2. 循环冗余校验(CRC)
				1. 思想<br>
					先在要发送的帧后面附加一个数，这个附加的数不是随意的，它要使加上这个数后所生成的新帧能与发送端和接收端共同选定的某个特定数整除（采用模2除法）。<br>
					到达接收端后，再把接收到的新帧除以（同样采用模2除法）这个选定的除数。因为在发送端发送数据帧之前就已附加了一个数，做了去余处理（也就已经能整除了），所以结果应该没有余数。如果有余数，则表明该帧在传输过程中出现了差错。
				2. 模2除法<br>
					与算术除法类似、但它既不向上位借位，也不比较除数和被除数的相同位数值的大小，只以相同位数进行相除。
				3. CRC校验码的计算示例<br>
					**TODO**<br>
					可参考：https://zhuanlan.zhihu.com/p/52665008
		3. 差错纠正<br>	
			**TODO**<br>
			可参考：https://zhuanlan.zhihu.com/p/52665008


3. 协议
	1. 点对点协议PPP<br>
		PPP是数据链路层使用最多的一种协议，它的特点是：简单，只检测差错而不去纠正差错，不使用序号，也不进行流量控制，可同时支持多种网络层协议。如我们在使用 Modem 进行拨号连接时就需要用到它，路由器设备间的 Serial 口之间的连接也要封装这个协议
	2. PPPoE是为宽带上网的主机使用的链路层协议

4. 网络设备
	1. 计算机网卡
	2. 网桥
	3. 二层交换机（注意是二层）

5. 参考
	1. https://zhuanlan.zhihu.com/p/52665008
	2. https://github.com/it-interview/EasyJob/blob/master/Network/network.md
	3. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#%E5%85%AB-http%E9%95%BF%E8%BF%9E%E6%8E%A5%E3%80%81%E7%9F%AD%E8%BF%9E%E6%8E%A5 

----

<span id = "network_network_layer"></span>
#### 网络层 [(TOP)](#home)
1. 概述
	1. 作用<br>
		**计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。**
	
	2. 数据单位<br>
		分组和包。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。

2. IP地址
	1. IP地址的表示
		IPv4的情况，IP地址是一个32位的二进制标识符<br>
		三种IP地址的表示：
		1. 分类IP地址
		2. 划分子网
		3. 构造超网

3. 分类的IP地址<br>
	1. 介绍<br>
 		分类的IP地址是指将固定的IP地址划分为若干个固定的类，每一类都有两个固定长度的字段组成。<br>
		IP地址::={<网络号>,<主机号>} 
		1. 其中第一个字段是网络号，标志着主机（路由器）所连接的网络，网络号是全网唯一的；
		2. 第二个字段是主机号，标志网络号所指的网络内的主机（路由器）。
	
	2. 分类<br>
		分类的IP地址根据网络号所占比特位个数不同，分为5类：A类、B类、C类、D类、E类，其中A、B、C类为单播地址，D类为多播地址，E类为保留地址。<br>
 		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_ip_type.png?raw=true)
		1. A类IP地址
			1. 网络号<br>
				A类地址的网络号字段占1个字节，但前面的1位(0)已经固定，只剩下7位可以进行分配，即可指派的网络号是126个(即2^7-2)。<br>
				减去2是因为：
				1. 网络号字段为全0的IP地址是个保留地址，意思是“本网络”；
				2. 网络号为127(即01111111)保留作为本地软件环回测试(loopback test)本主机的进程之间的通信只用。
			
			2. 主机号<br>
			 	A类地址的主机号占3个字节，因此每一个A类网络中的最大主机数是2^24-2，即16777214。<br>
				减去2是因为：
				1. **全0的主机号字段表示该IP地址是“本主机”所连接到的单个网络地址(例如，一主机的IP地址为5.6.7.8，则该主机所在的网络地址就是5.0.0.0)。**
				2. **全1的主机号字段表示该IP地址是“所有的”，即该网络上的所有主机。**
			 
		2. B类IP地址
			1. 网络号<br>
				B类地址的网络号字段占2个字节，但前面的2位(1 0)已经固定，只剩下14位可以进行分配。因为128.0.0.0是保留地址，所以指派的B类最小网络地址是128.1.0.0，可指派的网络数是2^14-1，即16383。
				
			2. 主机号<br>
				B类地址的主机号占2个字节，每一个网络上的最大主机数是2^16-2，即65534，这里需要减2是因为要扣除全0和全1的主机号。 
			
		3. C类IP地址	
			1. 网络号<br>
				C类地址的网络号字段占3个字节，但前面的3位(11 0)已经固定，只剩下21位可以进行分配。因为192.0.0.0是不指派的，而可以指派的C类最小网络地址是192.0.1.0。因此C类地址可指派的网络数是2^21-1，即2097151
			2. 主机号<br>
				C类地址的每一个网络上的最大主机数是2^8-2，即254，这里需要减2是因为要扣除全0和全1的主机号。
	
	3. IP地址分类的原因<br>
		各种网络差异很大，有些网络拥有很多主机，有些网络拥有的主机相对较少，把IP地址划分为A类、B类、C类能更好的满足需求，当某个单位申请了一个IP地址时，实际是获得了同样网络号的一个IP地址块，其中的各台主机号则由单位自行分配。	
		
	4. IP地址分的缺点<br>
		1. IP地址空间的利用率有时候很低，地址浪费大<br>
			A类拥有超过65535台主机；B类拥有介于255~65535台主机；C类拥有小于255台主机<br>
			只有两、三台主机的网络，也至少要一个C类IP地址;A、B类浪费更严重，少有达上万台主机的大型IP网络。
		2. 路由表太大，影响网络性能<br>	
 			路由器需要能够从路由表中找出怎样到达其他网络的下一跳地址，而一个物理网络对应一个网络号，如果网络越多，则路由表越大，路由器的存储空间就需要越大，查找也更耗时。<br>
 			解决方法：使用构造超网，则能减少网络数，提升性能。
		3. 不够灵活<br>	
 			企业有很多部门，每个部门可能需要各自独立的网络，这怎么办呢？再申请网络？可是人数又不多，怎么办呢？<br>
 			解决方法：划分子网，而且便于管理。
 			
3. 划分子网 
	1. 概念<br>
		划分子网是指将IP类网划分为若干个子网。一般是从网络的主机号用若干位作为子网号（当然用来分配的主机号就相应减少），于是二级网络便成了三级网络。<br>
	<img src="https://github.com/yinfork/Android-Interview/blob/master/res/network/network_subnet.png?raw=true" width = "255px" height = "63px" /> <br>
 		划分子网后，发送到子网某台主机的IP数据报，仍是根据IP数据报的目的网络号找到连接到路由器，然后路由器根据IP数据报的目的网络号和子网号找到子网，再把IP数据报交付主机。<br>
 		划分子网后，ip地址的网络号是不变的，因此在局域网外部看来，这里仍然只存在一个网络，即网络号所代表的那个网络；但在网络内部却是另外一个景象，因为我们每个子网的子网号是不同的，当用化分子网后的ip地址与子网掩码做'与'运算时，每个子网将得到不同的子网地址，从而实现了对网络的划分。
	
	2. 子网掩码<br>
		1. 概念<br>
	 		子网掩码是一个应用于TCP/IP网络的32位二进制值，它可以屏蔽掉ip地址中的一部分，从而分离出ip地址中的网络部分与主机部分，基于子网掩码，管理员可以将网络进一步划分为若干子网。
		2. 为什么需要子网掩码<br>
	 		IP数据报中是没有子网的相关信息，这时可以通过将本机的子网掩码与接受方主机的ip地址进行'与'运算，即可得到目标主机所在的网络号，又由于每台主机在配置TCP/IP协议时都设置了一个本机ip地址与子网掩码，所以可以知道本机所在的网络号。<br>
	 		通过比较这两个网络号，就可以知道接受方主机是否在本网络上。如果网络号相同，表明接受方在本网络上，那么可以通过相关的协议把数据包直接发送到目标主机；如果网络号不同，表明目标主机在远程网络上，那么数据包将会发送给本网络上的路由器，由路由器将数据包发送到其他网络，直至到达目的地。
	 		
		3. 子网掩码得到网络/主机地址的计算	
			1. 将ip地址与子网掩码转换成二进制；
			2. 将二进制形式的ip地址与子网掩码做'与'运算，将答案化为十进制便得到网络地址；
			3. 将二进制形式的子网掩码取'反'；
			4. 将取'反'后的子网掩码与ip地址做'与'运算，将答案化为十进制便得到主机地址。
			5. 例子<br>
				假设有一个IP 地址：192.168.0.1<br>
				子网掩码为：255.255.255.0<br>
				化为二进制为：IP地址11000000.10101000.00000000.00000001<br>
				子网掩码11111111.11111111.11111111.00000000<br>
				将两者做'与'运算得：11000000.10101000.00000000.00000000<br>
				将其化为十进制得：192.168.0.0<br>
				这便是上面ip的网络地址，主机地址以此类推，得到主机地址是1
				
		4. 子网掩码的分类
			1. 缺省子网掩码<br>
				即未划分子网，对应的网络号的位都置1，主机号都置0。
				1. A类网络缺省子网掩码：255.0.0.0
				2. B类网络缺省子网掩码：255.255.0.0
				3. C类网络缺省子网掩码：255.255.255.0
			2. 自定义子网掩码<br>	
	 			将主机号分为两个部分：子网号、子网主机号。
				1. 未做子网划分的ip地址：网络号＋主机号
				2. 做子网划分后的ip地址：网络号＋子网号＋子网主机号

	3. 划分子网的利弊
		1. 好处
			1. 划分子网一个最为重要意义就在于减少广播所带来的负面影响，提高性能的整体性能。因为广播数据包只能在同一网段中传输，网络规模小了，网络中用户数少了，当然所占用的资源也就少了。
			2. 节省了IP地址资源
			3. 由于不同子网之间是不能直接通信的（但可通过路由器或网关进行），在网络安全形势不容乐观的今天，网络越小，安全性就相对越高，因为入侵的途经小了。
			4. 便于维护 
		2. 缺点
			1. 可连接的主机数减少。
			2. 至于各子网间不能直接通信，可以说是既是它的利，又是它的害，会带来诸多的不便。
	
4. 无分类编址CIDR（构造超网）
	1. 出现背景<br>
		对于A、B类地址，很少有这么大规模的公司能够使用，而C类地址所容纳的主机数又相对太少。所以有类别的IP地址并不利于有效地分配有限的地址空间，不适用于网络规划。<br>
		在这种情况下，人们开始致力于下一代因特网协议——IPv6的研究。由于现在IPv6的协议并不完善和成熟，需要长期的试验验证，因此，IPv4到IPv6的完全过渡将是一个比较长的过程，在过渡期间我们仍然需要在IPv4上实现网络间的互连。所以引入了变长子网掩码（VLSM）和无类域间路由（CIDR）等机制，作为目前过渡时期提高IPv4地址空间使用效率的短期解决方案起到了很大的作用。
	
	2. 解决的问题
		1. 大小比较适中的B类IP地址的严重匮乏。
		2. 因特网主干网上的路由表中的项目数急剧增长。
		3. Ipv4地址迟早被分配完，到时候再无IP地址可以分配。
	
	3. 实现原理
		1. 消除传统的A，B，C地址和划分子网的概念，更有效的分配IPv4的地址空间，CIDR使IP地址又回到无分类的两级编码。记法：IP地址::={<<网络前缀>，<<主机号>}。CIDR还使用“斜线记法”即在IP地址后面加上“/”然后写网络前缀所占的位数（192.198.80.72/22）
		2. CIDR把网络前缀都相同的连续IP地址组成一个“CIDR地址块”，即强化路由聚合（构成超网）。一个CIDR地址块中有很多地址，所以在路由表中就利用CIDR地址块来查找目的网络。这种地址的聚合常称为路由聚合，它是的路由表中的一个项目可以表示原来传统分类地址的很多个理由。路由聚合也称为构成超网。路由聚合有利于减少路由器之间的路由选择信息的交换，从而提高了整个因特网的性能。
	
	4. 与划分子网的区别
		1. 子网是把网络拆分，而超网则是把网络聚合。
		2. 为了更方便地进行路由选择，CIDR使用32位的地址掩码。地址掩码是一串1和一串0组成，而1的个数就是网络前缀的长度。虽然CIDR不使用子网了，但由于目前仍有一些网络还使用子网划分和子网掩码，因此CIDR使用的地址掩码也可以继续称为子网掩码。斜线记法中，斜线后面的数字就是地址掩码中1的个数。 
	
	5. 构成超网的几个规则
		1. 构成超网的地址块数必须是2的N（N＝1、2、3……)次幂。
		2. 构成超网的地址块（超块）必须是连续的地址块。
		3. 超块的第一个地址的第三字节必须能够被块数均匀的分开（开始地址必须能被地址数N整除）

6. 交换机、网关与路由器<br>
	1. 交换机<br>
		1. 原理<br>
			交换机拥有一条很高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背部总线上，控制电路收到数据包以后，处理端口会查找内存中的MAC地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口，目的MAC若不存在，广播到所有的端口，接收端口回应后交换机会“学习”新的MAC地址，并把它添加入内部MAC地址表中。
		2. 大多数交换机工作于OSI参考模型的第二层，即数据链路层。
		3. 只是对数据转发和过滤，不会重新打包数据
	
	2. 	网关
		1. 网关在网络层以上实现网络互连
		2. 与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求 
		3. **TODO:RIP协议、端口映射**
		4. TODO：了解网关和默认网关、网段
		
	3. 默认网关<br>
		默认网关事实上不是一个产品而是一个网络层的概念，PC本身不具备路由寻址能力，所以PC要把所有的IP包发送到一个默认的中转地址上面进行转发，也就是默认网关。<br>
		在主机的网络属性配置中，除了有自身的逻辑IP地址，还有默认的网关地址。默认网关地址就是用来不同网络之间的主机进行通信的一扇门。只有通过默认网关，主机的数据包才能够被发送到不同网络的主机中。<br>
		这个默认网关可以在路由器上，可以在三层交换机上，可以在防火墙上，可以在服务器上，所以和物理的设备无关。
		
	4. 路由器<br>
		提供了路由与转送两种重要机制
		1. 可以决定数据包从来源端到目的端所经过的路由路径（host到host之间的传输路径），这个过程称为路由；
		2. 将路由器输入端的数据包移送至适当的路由器输出端(在路由器内部进行)，这称为转送	
	5. 区别<br>
		**TODO**<br>
		简单介绍:<br>
		要使网络A和网络B能够通信，只使用网关将这两个网络连接即可，因为只有两个网络，不需要决定网络间最短路径。
		如果需要连接多个网络，为了保证网络的可靠性，网络结构需要设计为全网状或部分网状，这样，为了网络间的通信，需要网关和路由器两种设备。

7. 路由转发基本流程<br>
	![](https://github.com/yinfork/Android-Interview/blob/master/res/network/ip_route_demo.png?raw=true)<br>
	假设主机甲要跟主机乙进行通信，那么主机甲如何才能够找到主机乙的位置？
	1. 当用户在主机甲上输入PING 172.168.80.8之后，主机甲中有一个网际控制报文协议ICMP。这个协议将创建一个回应请求数据包，在它的数据域中只包含有字母。
	2. 网际控制报文协议会将这个有效负荷(即刚创建的数据包)交给网际协议IP。<br>
		这个网际协议也会创建一个数据包。在这个网际协议IP创建的数据包中，在这个包中包括主机甲的IP地址、目的地主机已的IP地址以及值为01h的协议字段。当数据包到达主机乙时，这些内容就是告诉对方，应该将这个有效负荷交给网际控制报文协议来处理。
	3. IP协议会判断目的IP地址是属于远程网络，还是在本地网络。<br>
		由于根据IP地址规划规则，主机甲与主机乙属于不同的网络。此时，刚才网际协议IP所创建的数据包将会被发送到默认的网关中去。<br>
		在主机甲的网络属性配置中，除了有自身的逻辑IP地址，还有默认的网关地址。网关地址就是用来不同网络之间的主机进行通信的一扇门。只有通过网关，主机甲的数据包才能够被发送到不同网络的主机乙中。
	4. 确认路由器相应接口的MAC地址<br>
		假设主机甲(IP地址为172.168.60.6)的默认网关被配置为172.168.60.1。若主机甲的数据包要发送到这个默认网关上，则就必须知道其对应的路由器接口的物理地址，即MAC地址。得到目标IP的MAC地址后，数据包将会被释放并传递到数据链路层并生成帧。其中目的方的硬件地址也将同数据包一起下传到数据链路层。<br>
		当主机甲要把数据包发送给特定的网关时，必须要知道这个网关所对应的MAC地址。以下是简要的ARP过程：
		1. 主机甲首先会检查自己的ARP缓存，查看一个默认网关的IP地址是否已经解析为对应接口的硬件地址。
		2. 如果不存在，则将ARP请求帧广播到本地网络上的所有主机。
		3. 本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配
		4. 如果匹配，则目标主机将包含其MAC地址的ARP回复消息直接发送回主机甲。
		5. 当主机甲收到从目标主机发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。		
	
	5. 生成帧<br>
		当这个数据包和目的方的硬件地址被传递给数据链路层之后，一个数据帧即将产生，一旦完成帧的封装，则这个帧将会被交付到物理层。在这个帧中，主要包括:
		1. 目的MAC地址<br>
			这里指的目的地址并不是主机乙的地址，而是里主机甲最近的默认网关地址。在第一次通信时，主机甲并不知道主机乙的MAC地址。
		2. 源MAC地址(主机甲的MAC地址)
		3. 以太网类型字段<br>
			这个以太网类型字段主要用来描述的是交付这个数据包到数据链路层的网络层协议
		4. 数据包
		5. 帧校验序列<br>
			装载循环冗余校验计算值的区域
	6. 发送和接受帧
		1. 在主机甲所在的冲突域中的每台网络设备都将接收这些位并重新合并成数据帧。（冲突域是在同一个网络上两个设备同时进行传输则会产生冲突；冲突域就是连接在同一导线上的所有工作站的集合）
		2. 接收完毕后，他们会运行CRC过程并核对保存在帧校验序列字段中的内容。
		3. 如果这两个值不匹配的话，则这个帧将会被丢弃。如果两个值相同，则网络设备会接收这个帧，并核查目的方的硬件地址，检查他们是否也匹配。
		4. 如果目的方的硬件地址也是匹配的，那么路由器将会查看这个帧的以太网类型字段，以了解在网络层上采用了什么协议
		5. 然后路由器就会抽出帧中的数据包，把其余部分内容丢弃。然后把抽出来的数据包传送给以太网类型字段中列出的上层协议，如网际协议IP等等。
	7. 判断路由表项目。<br>
		网际协议IP会接收这个数据包，并检查目的IP地址。在这个案例中，由于数据包中的目的地址与接收路由器所配置的任何地址都不相匹配。此时，路由器就会在自己的路由表（**在路由表中，对每一条路由最主要的是以下两个信息：目的网络地址，下一跳地址**）中，查看目的IP的网络地址。在这个案例中，由于路由器同时连接着172.16.80.0的网络。所以在这个路由器的路由表中，有相关的纪录。若没有记录的话，则这个数据包会被直接丢弃。若路由器丢弃数据包的话，则会发送一个“目标地址不可达”的错误信息给主机甲。
	8. 路由器转发数据包<br>
		如果路由器的确在他的路由表中找到了相应网络的记录，则数据包就会被转发到输出接口。在本例中，就是主机乙所连接的接口。路由器会将这个数据包交换到对应接口的缓冲区内。
	9. 确认主机乙的MAC地址<br>
		路由器对应接口的缓冲区需要了解目的方主机的硬件地址。参考第四步，通过ARP缓存或者ARP请求获取主机乙的MAC地址。<br>
		路由器知道目的主机乙的MAC地址之后，就会把数据包连同目的方的MAC地址传递到下一层的数据链路中。
	10. 路由器会重复上面的第五步操作，生成数据帧。并传送到物理层，以一次一位的方式再发送到物理媒体上。在网络中进行传输。
	11. 主机乙会接收数据并响应ICMP协议<br>
		1. 主机乙会接收到这个数据帧并运行CRC过程
		2. 如果运算结果与帧校验序列中字段的内容相同，则这个帧中目的方的MAC地址将会被读取
		3. 主机乙会判断这个MAC地址是否跟自己的MAC地址相同
		4. 若相同的话，则会抽取其中的数据包，并根据以太网字段类型中指定的协议，把数据包传递给相应的协议处理
		5. 由于这个是ICMP协议的数据包，所以交给ICMP协议处理。ICMP协议会应答这个请求，同时把这个数据包丢弃并迅速生成一个新的有效负荷来作为回应应答。
		6. 主机乙会利用同样的过程把数据包以及目的MAC地址(路由器对应接口的物理地址)传递到下一层，让其生成帧。<br>
			在数据帧上，会带有目的MAC地址、源MAC地址、数据包、以太网字段类型、帧校验序列字段等内容发送到下一层。然后再一位位的传送到物理媒体
	12. 路由器再重复第六步到第十步的过程，把数据包从一个接口交换传递到另一个接口中。然后主机甲就收到一个回应信息，表示到主机乙的道路是通的。		
	13. 小结
		1. 第一到五步主要都是在主机甲上完成。这五个步骤执行完毕之后，IP路由选择过过程的前期工作就算完成了。
		2. 第六到十步是网际协议IP路由选择的步骤。可以看出路由器的作用主要就是进行数据交换。把其收到的数据包根据一定的规则转发到另一个可达的接口上。<br>
			路由器就好像是一个十字路口，各个数据包都根据自己所需要到达的目的地，现在合适的出口。	
		
8. 各种路由
	1. 静态路由<br>
		指由网络管理员手工配置的路由信息。当网络的拓扑结构或链路的状态发生变化时，网络管理员需要手工去修改路由表中相关的静态路由信息。静态路由信息在缺省情况下是私有的，不会传递给其他的路由器，但也可以设置使之成为共享的。<br>
		静态路由一般适用于比较简单的网络环境，在这样的环境中，网络管理员易于清楚地了解网络的拓扑结构，便于设置正确的路由信息。
	2. 动态路由<br>
		是指路由器能够自动地建立自己的路由表，并且能够根据实际实际情况的变化适时地进行调整。动态路由机制的运作依赖路由器的两个基本功能：对路由表的维护；路由器之间适时的路由信息交换。
	3. 特定主机路由<br>
		即对特定的目的主机指明的一个路由。这种路由叫做特定主机路由。<br>
		采用特定主机路由的好处：
		1. 可使网络管理人员能够更方便地控制网络和测试网络，同时也可在需要考虑某种安全问题时采用这种特定主机路由。
		2. 在对网络的连接或路由表进行排错时，指明到某一主机的特定路由就十分有用。
	
	4. 默认路由<br>
		默认路由是一种特殊的静态路由，指的是当路由表中与包的目的地址之间没有匹配的表项时路由器能够做出的选择。<br>
		如果没有默认路由，那么目的地址在路由表中没有匹配表项的包将被丢弃。<br>
		默认路由在某些时候非常有效，当存在末梢网络时，默认路由会大大简化路由器的配置，减轻管理员的工作负担，提高网络性能。<br>
		主机里的默认路由通常被称作默认网关，默认网关通常会是一个有过滤功能的设备，如防火墙和代理服务器。
	
9. 分类IP路由分组转发算法
	1. 从数据报的首部提取目的主机的IP地址D，得出目的网络地址为N。
	2. 若N就是与此路由器直接相连的某个网络地址，则进行直接交付，不需要再经过其他的路由器，直接把数据报交付给目的主机（这里包括把目的主机地址D转换为具体的硬件地址，把数据报封装为MAC帧，再发送此帧）；否则就要执行(3)进行间接交付。
	3. 若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器，否则执行(4)。
	4. 若路由表中有到达网络N的路由，则把数据报传送给路由表中所指明的下一跳路由器，否则执行(5)。
	5. 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的下一跳路由器，否则执行(6)。
	6. 报告转发分组出错。
		
10. 划分子网下的分组转发<br>
	**使用子网划分后，路由表必须包含以下三项内容：目的网络地址、子网掩码和下一跳地址。**<br>
在划分子网的情况下，路由转发分组的算法如下(和没划分子网的情况比较下，大体的流程是不变的)：
	1. 从收到的数据报的首部提取目的IP地址D。
	2. 先判断是否为直接交付。对路由器直接相连的网络逐个进行检查：用各网络的子网掩码和D逐位相“与”（AND操作），看结果是否和相应的网络地址匹配。若匹配，则把分组进行直接交付（还需把D转换成物理地址，把数据报封装成帧发送出去），转发任务结束。否则就是间接交付，执行（3）。
	3. 若路由表中有目的地址为D的特定主机路由，则把数据报传送给路由表中所指明的下一跳路由器；否则，执行（4）。
	4. 对路由表中的每一行（目的网络地址、子网掩码、下一跳地址），用其中的子网掩码和D逐位相“与”（AND），其结果为N。若N与该行的目的网络地址匹配，则把数据报传送给该行指明的下一跳路由器；否则，执行（5）。
	5. 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；否则，执行（6）。
	6. 报告转发分组出错。

11. 构造超网下的分组转发<br>
	在使用使CIDR时，由于采用了网络前缀这种记法，IP地址由网络前缀和主机号这两个部分组成，因此在路由表中的项目也要有相应的改变。这时，**路由表中的每个项目由“网络前缀”和“下一跳地址”组成。**<br>
	但是在查找路由表时可能会得到不止一个匹配结果。这个时候我们应当从匹配结果中**选择具有最长网络前缀的路由，这叫作最长前缀匹配。**即选择两个匹配结果中地址更具体的一个。<br>
	路由转发分组的算法和分类IP、划分子网的路由转发时差不多，只是第二步改成利用网络前缀来判断是否为直接交付

12. 配套的四个协议
	1. ARP（Address Resolution Protocol）地址解析协议<br>
		1. 作用：IP地址 -> MAC地址
		2. 过程：<br>
			当主机A的IP地址为192.168.1.1，MAC地址为0A-11-22-33-44-01；<br>
			主机B的IP地址为192.168.1.2，MAC地址为0A-11-22-33-44-02；<br>
			以下为工作流程：
			1. 根据主机A上的路由表内容，IP确定用于访问主机B的转发IP地址是192.168.1.2。然后A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址。
			2. 如果主机A在ARP缓存中没有找到映射，它将询问192.168.1.2的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。
			3. 主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。
			4. 主机B将包含其MAC地址的ARP回复消息直接发送回主机A。
			5. 当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。
		
	2. RARP（Reverse Address Resolution Protocol）逆地址解析协议（已经被淘汰）<br>
		MAC地址 -> IP地址	
	
	3. ICMP（Internet Control Message Protocol）因特网控制报文协议 <br>
		用于TCP/IP网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，令管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。比如常见的Ping命令
	
	4. IGMP（Internet Group Management Protocol）因特网组管理协议<br>
		用于管理网路协议多播组成员的一种通信协议。IP主机和相邻的路由器利用IGMP来创建多播组的组成员。


13. IP数据报<br>
	![](https://github.com/yinfork/Android-Interview/blob/master/res/network/network_ip_data.png?raw=true)

14. 其他常用协议和工具
	TODO:路由选择协议、OSPF（开放式最短路径优先）、BGP（边界网关协议）、DHCP（动态主机设置协议）、NAT（地址转换协议）<br>
	参考：https://github.com/hadyang/interview/blob/master/basic/net/base_protocol.md
	<br><br>
	工具：<br>
	Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具

15. 参考
	1. https://www.jianshu.com/p/155d4bfcdac1
	2. https://www.jianshu.com/p/1165bfc708c0
	3. https://www.jianshu.com/p/8c8c1d1f2344
	4. https://zhuanlan.zhihu.com/p/37820182
	5. https://zhuanlan.zhihu.com/p/26098552
	6. https://github.com/Snailclimb/JavaGuide/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#%E5%85%AB-http%E9%95%BF%E8%BF%9E%E6%8E%A5%E3%80%81%E7%9F%AD%E8%BF%9E%E6%8E%A5
	7. https://github.com/hadyang/interview/blob/master/basic/net/base_protocol.md
		
----

<span id = "network_transport_layer"></span>
#### 运输层 [(TOP)](#home)
1. 作用<br>
	**运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。**网络层的IP协议可以将数据包送到目的主机，但并未交付到具体的进程，而运输层则提供了应用进程之间的逻辑通信，同时还负责对收到的报文进行差错检查。

2. 端口<br>
	协议端口号（简称端口）是运输层的概念，当网络层将数据包送达主机时必须能够知道其希望与主机的哪一个进程进行交互，而端口号即标识了具体的某一个进程
	1. 服务端使用的端口号（0~49151）<br>
		服务端的端口号也分为两类：系统端口号和登记端口号。系统端口号范围是0~1023，是被IANA指派到一些特定应用的端口号，例如FTP是21，HTTP是80等。而登记端口号范围1024~49151，必须按照IANA规定程序登记方可使用。
	2. 客户端使用的端口号（49152~65535）<br>
		这些端口号是客户端进程运行时动态选择临时使用，和服务端通信时，服务端将响应报文发回至客户端相应的临时端口号，通信结束后这个端口号可能就已经被别的客户端进程使用了。

3. 运输层主要使用以下两种协议
	1. 传输控制协议 TCP（Transmisson Control Protocol）--提供面向连接的，可靠的数据传输服务。
	2. 用户数据协议 UDP（User Datagram Protocol）--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。
	3. 常见应用层协议对应的运输层协议图<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/common_protocol.png?raw=true)

4. UDP协议
	1. 简介<br>
		**UDP只在IP层的数据报上添加了很少的功能，包括端口信息和差错检测，UDP首部只有8个字节（TCP头部有20字节）。<br>
		UDP是传输层协议，并不提供超时重传，出错重传等功能，也就是说其是不可靠的协议。<br>**
		UDP协议主要用来支持那些需要在计算机之间传输数据的网络应用。包括网络视频会议系统在内的众多的C/S模式的网络应用都需要使用UDP协议。UDP协议直接位于IP（网际协议）协议的顶层。
	2. 特点
		1. 无连接，发送数据之前不需要建立连接。开销减少和发送之前的时间延迟较短。
		2. 尽最大努力交付（可以采取一定策略实现可靠传输）。
		3. 面向报文，UDP对应用程序交付的报文，添加UDP首部后直接交给IP层。不合并，不拆分。
		4. 没有拥塞控制，网络拥塞不会使源主机发送率降低。
		5. UDP支持一对一，一对多，多对一的交互通信。
		6. UDP首部开销较小，8字节（TCP为20字节、IP为20字节）。
	3. UDP首部的格式<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/udp_head.png?raw=true)
		<br>
		首部由8个字节四个部分组成，每个部分由2个字节。
		1. 源端口：在需要交互方回信的时候选用，不需要回信使用0。
		2. 目的端口：在终点交付报文的时候必须使用。
		3. 长度：udp用户数据报的长度，最小为8。
		4. 检验和：检测udp数据报在传输中是否有错误，有错就将其丢弃。（在计算检验和的时候，要在udp用户数据报之前添加12个字节的伪首部，伪首部既不下传递也不向上递交，作用仅为计算检验和）
		5. 伪首部
			1. 伪首部是不占地址空间的，在实际传输中不存在这样的字段。只是在使用的时候把它拿出来设置一下
			2. 设置伪首部只是为了计算检验和。其目的是让UDP两次检查数据是否已经正确到达目的地。如何两次检验？<br>
				1. 第一次，通过伪首部的IP地址检验，UDP可以确认该数据报是不是发送给本机IP地址的；
				2. 第二次，通过伪首部的协议字段检验，UDP可以确认IP有没有把不应该传给UDP而应该传给别的高层的数据报传给了UDP。

5. TCP协议
	1. 简介<br>
		TCP（Transmission Control Protocol）传输控制协议是一种面向连接的、可靠的、基于字节流的传输层（Transport layer）通信协议，在1981年由IETF的RFC 793正式提出。
TCP的主要功能是在互联网中为提供可靠的、面向连接的进程间通信服务。
	2. 特点
		1. 面向连接的传输;
		2. 端到端的通信;
		3. 高可靠性，确保传输数据的正确性，不出现丢失或乱序;
		4. 全双工方式传输;
		5. 采用字节流方式，即以字节为单位传输字节序列;
		6. 紧急数据传送功能;	
	3. TCP首部的格式<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/network/tcp_head.png?raw=true)<br>
		1. 源端口和目的端口（Source Port和Destination Port）：分别占用2个字节，用于区别主机中的不同进程，而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接。
		2. 序号seq（Sequence Number）：占4个字节，用来标识从TCP发端向TCP收端发送的数据字节流（tcp传输的每一个字节都按顺序编号），主要用来解决网络报乱序的问题。
			1. 如果含有同步化旗标（SYN），则此为最初的序列号；第一个数据比特的序列码为本序列号加一。
			2. 如果没有同步化旗标（SYN），则此为第一个数据比特的序列码。
		3. 确认号ack（Acknowledgment Number）：占4个字节，确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志为1时该确认序列号的字段才有效。主要用来解决不丢包的问题（确认序号减去上次收到的序号等于本段收到的报文的长度）。
		4. 数据偏移（Offset）：占4个bit，指出tcp报文段的数据起始处距离tcp报文段的起始有多远，这个字段实际指出Ttcp报文段的首部长度。需要这个值是因为任选字段的长度是可变的，它用来表示首部中32bit（4字节）字的数目，因此最多能表示15个32bit的的字，即4*15=60个字节的首部长度），因此TCP最多有60字节的首部。然而，没有任选字段，正常的长度是20字节。
		5. 保留（3比特长）—须置0
		6. 标志符（9比特长）<br>
			1. NS：ECN-nonce。
			2. CWR：Congestion Window Reduced。
			3. ECE：ECN-Echo有两种意思，取决于SYN标志的值。
			4. URG：为1表示高优先级数据包，紧急指针字段有效。告诉系统这个报文段中有紧急数据，应当尽快传输。
			5. ACK：为1表示TCP头部的确认号字段有效，反之为0
			6. PSH：为1表示是带有PUSH标志的数据，指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。
			7. RST：表示连接复位请求，为1表示出现严重差错。可能需要重现创建TCP连接。还可以用于拒绝非法的报文段和拒绝连接请求。
			8. SYN：为1表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步。
				1. 创建连接时，SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1；
				2. 被用作端口扫描<br>
					这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手。
			9. FIN：为1表示发送方没有数据要传输了，要求释放连接。
		7. 窗口：占2个字节，表示从确认号开始，本报文的接受方可以接收的字节数，即接收窗口大小。用于流量控制。
		8. 检验和：占2个字节。—对整个的TCP报文段，包括TCP头部和TCP数据，以16位字进行计算所得。这是一个强制性的字段。
		9. 紧急指针：占2个字节。本报文段中的紧急数据的最后一个字节的序号。
		10. 选项和填充：40字节。每个选项的开始是1字节的kind字段，说明选项的类型。填充是为了使TCP首部为4byte的整数倍。
			1. kind=0：选项表结束（1字节）
			2. kind=1：无操作（1字节）用于选项字段之间的字边界对齐。
			3. kind=2：最大报文段长度（4字节，Maximum Segment Size，MSS）通常在创建连接而设置SYN标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将MSS设置为（MTU-40）字节，携带TCP报文段的IP数据报的长度就不会超过MTU，从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。
			4. kind=3：窗口扩大因子（4字节，wscale），取值0-14。用来把TCP的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。这是因为现在的TCP接收数据缓冲区（接收窗口）的长度通常大于65535字节。
			5. kind=4：sackOK—发送端支持并同意使用SACK选项。<br>
				SACK含义：用于数据重传中的“选择确认”（selective acknowledgment，SACK）选项。RFC 2018对此定义为允许接收方确认它成功收到的分组的不连续的块，以及基础TCP确认的成功收到最后连续字节序号。
			6. kind=5：SACK实际工作的选项。
			7. kind=8：时间戳（10字节，TCP Timestamps Option，TSopt）
				1. 发送端的时间戳（Timestamp Value field，TSval，4字节）
				2. 时间戳回显应答（Timestamp Echo Reply field，TSecr，4字节）
	
	
	4. 常见名词
		1. 最大分段大小（MSS）<br>
			最大分段大小 (MSS)是在单个分段中TCP愿意接受的数据的字节数最大值。MSS应当足够小以避免IP分片，它会导致丢包或过多的重传。在TCP连接创建时，双端在SYN报文中用MSS选项宣布各自的MSS，这是从双端各自直接相连的数据链路层的最大传输单元(MTU)的尺寸减去固定的IP首部和TCP首部长度。
		2. 重传超时时间(RTO，Retransmission TimeOut)<br>
			TODO：RTO是怎么设定的
		3. 连接往返时间(RTT)
	
	5. TCP通过以下方式来提供可靠性
		1. 序列号<br>
			序列号是指按照顺序给发送数据包中的每一个字节都标识上号码编号。<br>
			作用：
			1. 应答
			2. 接收方对数据包进行排序，把有序数据传送给应用层
			3. 去掉重复的数据
			
		2. 确认应答处理<br>
			接收端主机根据接收数据TCP包首部中的序列号和数据长度，来将自己下一步应该接收的序列号作为确认应答返送回去，从而实现可靠传输

		3. 自动重传<br>
			自动重传请求是OSI模型中**数据链路层**和**传输层**的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送，实现可靠传输。<br>
			1. TCP使用两套独立的机制来完成重传<br>
				1. 基于时间的超时重传<br>
					TCP协议要求在发送端每发送一个报文段，就启动一个定时器并等待确认信息；接收端成功接收新数据后返回确认信息。若在定时器超时前数据未能被确认，TCP就认为报文段中的数据已丢失或损坏，需要对报文段中的数据重新组织和重传。
				2. 基于重复累计确认信息的快速重传<br>
					1. 优点<br>
						快速重传机制基于接收端的反馈信息来引发重传，而非基于计时器超时重传。与超时重传相比，快速重传能更加及时有效地修复丢包情况。
					2. 实现原理<br>
	       			快速重传机制要求当接收到失序报文段时，TCP需要立即生成确认信息（重复ACK），并且失序情况表明在后续数据到达前出现了丢包，发送端的工作即为尽快填补丢包带来的数据段空缺。
					3. 与拥塞控制的关系<br>
						根据重复ACK推断的丢包通常与网络拥塞有关，因此快速重传也会触发拥塞控制机制。
					4. 示例图<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/fast_resend.png?raw=true)<br>
			
			2. 重复累积确认信息下如何重传数据
				1. 回退N重传<br>
					接收点丢弃从第一个没有收到的数据包开始的所有数据包。发送点收到NACK后，从NACK中指明的数据包开始重新发送。
				2. 带选择确认的重传<br>
					1. 介绍<br>
						发送点连续发送数据包但对每个数据包都设有个一个计时器。当在一定时间内没有收到某个数据包的ACK时，发送点只重新发送那个没有ACK的数据包。（使用SACK选项）
					2. SACK
						1. 介绍<br>
							普通 TCP（即未提供 SACK 特性）应答是严格累积的：对 N 的应答意味着字节 N 和所有之前的字节都已经收到。SACK 要解决的问题普通累积式应答的 “全有或全无” 性质。
						2. 例子<br>
							包 2（假设从 0 到 9 的序列）是在传送过程中惟一丢失的包，接收方也只能对包 1 发出一个普通的 ACK，因为这是连续接收到的包中的最后一个。另一方面，SACK 接收方可以发出包 1 的 ACK 和包 3 到包 9 的 SACK 选项。这种附加信息可以帮助发送方确定丢失的包最少，只需重新传送很少的数据。如果没有这种附加信息，它需要重新传送大量的数据，这样会降低传送速率，从而适应高丢包率的网络。
						3. SACK数量<br>
							每个包中的最多包含 4 个 SACK 选项（假设使用了时间戳选项，最多则只有3个）
				
			3. 对应的实现协议<br>
				ARQ包括停止等待ARQ协议和连续ARQ协议
				1. 停止等待ARQ协议
					1. 原理<br>
						1. 发送点对接收点发送数据包，然后等待接收点回复ACK并且开始计时。
						2. 在等待过程中，发送点停止发送新的数据包。
						3. 当数据包没有成功被接收点接收时候，接收点不会发送ACK.这样发送点在等待一定时间后，重新发送数据包。<br>
							没成功接收到的情况：
							1. 所发送的数据丢失
							2. 确认消息丢失
							3. 确认消息延时
						4. 反复以上步骤直到收到从接收点发送的ACK.
					2. 示意图<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/stop_and_wait_arq.png?raw=true) 
					3. 缺点<br>
						TCP是以一个段为单位进行数据的传输的，每发送一个段，就会等待对端主机的针对这个段的确认应答信号ACK。较长的等待时间导致低的数据传输速度。
				2. 连续ARQ协议
					1. 原理<br>
						1. 为了克服停止并等待ARQ协议长时间等待ACK的缺点。这个协议会连续发送一组数据包，然后再等待这些数据包的ACK.
						2. 接受方采用累积确认的方式：接收方不必每收到一个消息，就发送一个确认。而是在收到几条消息后，对按序到达的最后一条消息发送确认。表示这个消息之前的所有消息全部收到。
					2. 两种重传的方式
						1. 回退N重传(Go-Back-N)<br>
							接收点丢弃从第一个没有收到的数据包开始的所有数据包。发送点收到NACK后，从NACK中指明的数据包开始重新发送。
						2. 选择重传(Selective Repeat)<br>
							发送点连续发送数据包但对每个数据包都设有个一个计时器。当在一定时间内没有收到某个数据包的ACK时，发送点只重新发送那个没有ACK的数据包。
					3. 示意图<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/continuous_arq.png?raw=true) 

		4. 重复处理<br>
			TCP 的接收端会丢弃重复的数据。
			
		5. 校验和<br>
			1. 计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。 
			2. 发送方：在发送数据之前计算检验和，并进行校验和的填充。 
			3. 接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。
		6. 连接管理<br>
			1. 三次握手<br>
				建立一个TCP连接需要三次握手
				1. 示意图<br>
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/tcp_connect.png?raw=true) 

				2. 流程
					1. 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
					2. 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
					3. 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端
				3. 三次握手的含义<br>
					三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的，缺一不可。
					1. 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常
					2. 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常
					3. 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常
				4. 为什么要传回 SYN<br>
					接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。
				5. 传了 SYN,为啥还要传 ACK<br>
					双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。
			
			2. 四次挥手<br>
				断开一个TCP连接需要四次挥手
				1. 示意图
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/tcp_disconnect.png?raw=true) 
				
				2. 流程
					1. 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
					2. 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号
					3. 服务器-关闭与客户端的连接，发送一个FIN给客户端
					4. 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1
				
				3. 为什么要四次挥手<br>
					任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。<br>
					举个例子：<br>
					A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。
				
		7. 使用滑动窗口协议实现流量控制<br>
			1. 滑动窗口的作用<br>
				1. 实现面向流的可靠性保证
					1. 发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界。
					2. 接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。

				2. 实现流量控制<br>
					1. 让发送端主机根据接收端主机的实际接收能力来控制自己发送的数据量<br>
						应用根据自身的处理能力变化，通过本端TCP接收窗口大小控制来对对对端的发送窗口流量限制。发送端主机会根据自己的实际情况发送数据，而接收端也会跟据自己的实际情况接收数据。
					2. 提高传输速度<br>
						TCP是以一个段为单位进行数据的传输的，每发送一个段，就会等待对端主机的针对这个段的确认应答信号ACK，但这样的传输方式的缺点也很明显，就是：当数据包的往返时间越长，通信性能越低。
						而使用滑动窗口后，确认应答包不再以每个段为单位进行确认了，而是以更大的单位进行确认，转发时间将会被大幅度的缩短。也就是说，发送端主机在发送了一个段之后，没必要一直等待对端主机的确认应答信号，而是继续发送。
			2. 窗口<br>
				TCP首部中，专门有一个字段用来通知“窗口大小”。接收端主机向发送端主机通知自己所能够接收数据的大小，于是发送端主机就会发送不超过这个限度的数据，这个值是由接收端主机决定的。TCP滑动窗口分为接受窗口，发送窗口：
				1. 发送窗口<br> 					发送窗口：无需等待接收端主机的确认应答信号而可以持续发送的数据的最大值<br>
					发送方任何时候在其发送缓存内的数据都可以分为4类，“已经发送并得到对端ACK的”，“已经发送但还未收到对端ACK的”，“未发送但对端允许发送的”，“未发送且对端不允许发送”。<br>
					其中“已经发送但还未收到对端ACK的”和“未发送但对端允许发送的”这两部分数据称之为发送窗口。<br>
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/sliding_window_classify.png?raw=true)
					
				2. 接收窗口<br>
					对于TCP的接收方，在某一时刻在它的接收缓存内存在3种。“已接收”，“未接收准备接收”，“未接收并未准备接收”（由于ACK直接由TCP协议栈回复，默认无应用延迟，不存在“已接收未回复ACK”）。其中“未接收准备接收”称之为接收窗口。
				3. 发送窗口与接收窗口关系<br>	
					TCP是双工的协议，会话的双方都可以同时接收、发送数据。TCP会话的双方都各自维护一个“发送窗口”和一个“接收窗口”。其中各自的“接收窗口”大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。各自的“发送窗口”则要求取决于对端通告的“接收窗口”，要求相同。
		
			3. 实现
				1. 建立连接后，接收端会告诉发送端，自己的"接收窗口"大小，发送端接收到接收端的"接收窗口"大小，就会变成发送端自己的"发送窗口"大小。因为TCP是双工的，同样发送端也会告诉接收端自己的接收窗口的大小。
				2. 当发送方收到接收方新的ACK，对于发送窗口中后续字节的确认时，窗口滑动。发送端窗口的第一个字节序号一定是ACK中期望收到的下一个字节序号<br>
					![](https://github.com/yinfork/Android-Interview/blob/master/res/network/sliding_window_demo.png?raw=true)
				3. 接收端主机的缓冲区一旦面临数据溢出，就会主动减小窗口的大小再次发送给发送端主机，从而可以控制数据发送量。也就是说，发送端主机会根据接收端主机的指示，对发送的数据量进行控制，这也就形成了一条完整的TCP流量控制。
			
			4. 当窗口大小为0时的探测处理<br>
				当接收方宣布接收窗口的值为0，发送方停止进一步发送数据，开始了“保持定时器”（persist timer），**以避免因随后的修改接收窗口的数据包丢失使连接的双侧进入死锁**，发送方无法发出数据直至收到接收方修改窗口的指示。当“保持定时器”到期时，TCP发送方尝试恢复发送一个小的ZWP包（Zero Window Probe），期待接收方回复一个带着新的接收窗口大小的确认包。一般ZWP包会设置成3次，如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。
					
			5. 示例<br>
				![](https://github.com/yinfork/Android-Interview/blob/master/res/network/sliding_window.png?raw=true)<br>
				client端和server端已经三次握手建立TCP连接，总窗口大小是TCP建立连接时候确定的。黑色框代表client和server总的窗口大小，红色框代表实际可用的窗口大小。初始化的时候默认client和server总窗口和可用端口分别都是360。另外，假设Client总共只发送360bytes数据，所以总窗口大小不会往前移动。
				1. client 发送140bytes到server端，Seq=1，Length=140；可用窗口大小往前移动，变成260bytes，总窗口大小不变，依然是360。这中间的120是已发送，等待确认;
				2. server端收到140bytes，放入buffer中，但是应用程序很繁忙，只取出100个字节。这时候可用窗口大小: 260(360-100)。接着server端要给client发确认，Ack=141，Window=260。黑框左边缘向前移动，表示140字节已经确认收到，但是应用程序太慢，处理很忙导致我现在只能处理260bytes(回顾下上面server端收到数据要做的两件事);
				3. client收到来自server端的ack回应，首先总窗口左边缘向前移动，表示第一步的140bytes server已经收到，剩下260数据。接着被告知server的可接收窗口是260，client就调整自己的发送窗口是260，表示一次发数据不能超过260;client发送180bytes，可用窗口变成80(260-180)，等待确认发送的180bytes;
				4. server收到180bytes，放入buffer中，应用程序依然很繁忙，这次一个字节都不处理。此时可用窗口大小:80(260-180)，然后发180 ack给client，并告知窗口大小80;
				5. client收到ack，确认之前发送的180已经到达，剩余数据还有80字节。被告知server端接收窗口大小是80，调整自己的发送窗口大小为80
				6. client发送80bytes，可用窗口变成0(80-80)，等待确认发送的80bytes;
				7. server收到180bytes，放入buffer中，应用程序依然很繁忙，一个字节都不处理。此时可用窗口大小:80(80-80)，然后发80 ack给client，并告知窗口大小0;
				8. client收到ack，确认之前发送的80已经到达。被告知server端接收窗口大小是0，调整自己的发送窗口大小为0，此时无论client是否还有数据要发送，都不能再发了。	
		
		8. 拥塞控制
			1. 问题背景<br>
				计算机网络都处在一个共享的环境中，如果网络上的延时突然增加，那么TCP对这个事做出的应对只有重传数据，但是重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。
			2. 解决思路<br>
				TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了
			3. 运作过程<br>
				1. TCP会为每条连接维护一个“拥塞窗口”来限制可能在端对端间传输的未确认分组总数量。
				2. TCP在一个连接初始化或超时后使用一种“慢启动”机制来增加拥塞窗口的大小。它的起始值一般为最大分段大小（MSS）的两倍，虽然名为“慢启动”，初始值也相当低，但其增长极快：当每个分段得到确认时，拥塞窗口会增加一个MSS，使得在每次往返时间（RTT）内拥塞窗口能高效地双倍增长。
				3. 当拥塞窗口超过慢启动阈值时，算法就会进入一个名为“拥塞避免”的阶段。在拥塞避免阶段，只要未收到重复确认，拥塞窗口则在每次往返时间内线性增加一个MSS大小。
			
			4. 拥塞控制的方法
				1. 拥塞窗口<br>
					拥塞窗口是任何时刻内确定能被发送出去的字节数的控制因素之一，是阻止发送方至接收方之间的链路变得拥塞的手段。他是由发送方维护，通过估计链路的拥塞程度计算出来的，与由接收方维护的接收窗口大小并不冲突。
				2. 慢启动<br>
					1. 慢启动的介绍<br>
						慢启动初始启动时设置拥塞窗口值为1、2、4或10个MSS。拥塞窗口在每接收到一个确认包时增加，每个RTT内成倍增加，当然实际上并不完全是指数增长，因为接收方会延迟发送确认，通常是每接收两个分段则发送一次确认包。发送速率随着慢启动的进行而增加，直到遇到出现丢失、达到慢启动阈值、或者接收方的接收窗口进行限制。
					2. 慢启动的缺点<br>
						1. 慢启动假设分段的未确认是由于网络拥塞造成的，虽然大部分网络的确如此，但也有其他原因，例如一些链路质量差的网络，会导致分段包丢失。在一些网络环境，例如无线网络，慢启动效率并不好。
						2. **慢启动对于一些短暂的连接性能并不好，一些较旧的网页浏览器会创建大量连续的短暂链接，通过快速开启和关闭链接来请求获得文件，这使得大多数链接处于慢启动模式，导致网页响应时间差。**所以现在新的网页浏览器，会通过向特殊的服务器，开启一条链接来请求获得全部的文件，而避免频繁新建大量短暂链接。
				
				3. 快重传<br>
					1. 普通的重传机制: TCP 的可靠传输的原理就是超时重传机制。配合上面的慢开始和拥塞避免使用就是发送发发送完数据后设置一个定时器，如果在定时器时间内没有收到对接收方发来的确认的话就去执行上述的乘法减小过程并重新开始慢开始算法。
					2. 快重传则是允许发送方再连续收到 3 个重复的确认后就可以开始执行乘法减小过程而不必再等待所设置的重传计时器到时。<br>
						但是快重传有两个实现算法，主要区别是是否进入慢启动：
						1. Tahoe(废弃)：如果收到三次重复确认，Tahoe算法则进入快速重传，将慢启动阈值改为当前拥塞窗口的一半，将拥塞窗口降为1个MSS，并重新进入慢启动阶段。
						2. Reno：如果收到三次重复确认，Reno算法则进入快速重传，只将拥塞窗口减半来跳过慢启动阶段，将慢启动阈值设为当前新的拥塞窗口值，进入一个称为“快速恢复”的新设计阶段。
					
				4. 快恢复<br>	
					快恢复算法是与快重传算法配合使用的一个算法(连续接收到三个重复的确认)。快恢复是快重传Reno算法新引入的一个阶段<br>
					使用了快恢复算法后与原来不同的一点是当发现网络出现拥塞并执行了乘法减小过程后，并不是设置cwnd=1并重新开始执行慢开始算法，而是让 cwnd =乘法减小后的ssthresh并开始执行拥塞避免算法。
					
				5. 拥塞避免<br>
					不能任由慢开始算法中的 cwnd 指数增长，所以我们引入一个慢开始门限（ssthresh）的阈值来控制 cwnd 的增长。
					1. 规则
						1. cwnd < ssthresh , 使用慢开始算法
						2. cwnd = ssthresh , 使用慢开始算法或拥塞避免算法都可以
						3. cwnd > ssthresh , 使用拥塞避免算法呢
					2. ssthresh的设置<br>
						TCP/IP 中规定无论是在慢开始阶段还是在拥塞避免阶段，只要发现网络中出现拥塞（没有按时收到确认），就要把ssthresh设置为此时发送窗口的一半大小（不能小于2）。
					3. 普通的拥塞避免过程<br>
						每个传输轮次后将 cwnd 的大小加一（加法增大），如果发现出现网络拥塞的话就按照上面的方法重新设置ssthresh的大小（乘法减小）并从cwnd=1开始重新执行慢开始算法。<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/congest.png?raw=true)
					4. 使用了快重传和快恢复的拥塞避免过程<br>						每个传输轮次后将 cwnd 的大小加一（加法增大），如果发现出现网络拥塞的话就按照上面的方法重新设置ssthresh的大小（乘法减小），然后并不是设置cwnd=1并重新开始执行慢开始算法，而是让 cwnd =乘法减小后的ssthresh并开始执行拥塞避免算法。<br>
						![](https://github.com/yinfork/Android-Interview/blob/master/res/network/congest_fast.png?raw=true)
				
			5. 拥塞控制与流量控制的区别<br>
				1. 拥塞控制就是防止过多的数据注入到网络中，这样可以防止网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。流量控制往往指点对点通信量的控制，是个端到端的问题。
				2. 流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。
		9. 应用数据被分割成 TCP 认为最适合发送的数据块<br>
			对应的概念：最大分段大小 (MSS)

10. 参考
	1. https://www.jianshu.com/p/ca2289a15b06 
	2. https://www.jianshu.com/p/97e5d7e73ba0
	3. https://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6
	4. https://www.jianshu.com/p/8afbbdd4af48
	5. https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE
	6. https://www.zhihu.com/question/32255109
	7. https://zh.wikipedia.org/wiki/%E8%87%AA%E5%8A%A8%E9%87%8D%E4%BC%A0%E8%AF%B7%E6%B1%82
	8. https://blog.csdn.net/qq_37653144/article/details/82743760
	9. https://blog.csdn.net/cmm0401/article/details/77878998

----

<span id = "network_application_layer"></span>
#### 应用层 [(TOP)](#home)
1. 定义<br>
	通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。

2. 常见协议
	1. Http
	2. DNS 

3. Http协议详解



