## 计算机基础
<span id = "home"></span>
#### 目录
1. [IO操作](#computer_io)
2. [进程与线程](#process_thread)
3. [死锁](#deadlock)
4. [加密算法](#encrypt)

----

<span id = "computer_io"></span>
#### IO操作 [(TOP)](#home)
1. 传统的标准IO操作<br>
	1. 介绍<br>
		传统的 Linux 操作系统的标准 I/O 接口是基于数据拷贝操作的，即 I/O 操作会导致数据在操作系统内核地址空间的缓冲区和应用程序地址空间定义的缓冲区之间进行传输。这样做最大的好处是可以减少磁盘 I/O 的操作，因为如果所请求的数据已经存放在操作系统的高速缓冲存储器中，那么就不需要再进行实际的物理磁盘 I/O 操作。但是数据传输过程中的数据拷贝操作却导致了极大的 CPU 开销，限制了操作系统有效进行数据传输操作的能力。
	
	2. Linux中传统服务器进行数据传输的流程<br>
		![](https://github.com/yinfork/Android-Interview/blob/master/res/computer/io_read_write.png?raw=true)
		1. 当应用程序需要访问某块数据的时候，操作系统内核会先检查这块数据是不是因为前一次对相同文件的访问而已经被存放在操作系统内核地址空间的缓冲区内
		2. 如果在内核缓冲区中找不到这块数据，Linux 操作系统内核会先将这块数据从磁盘读出来放到操作系统内核的缓冲区里去。如果这个数据读取操作是由 DMA 完成的，那么在 DMA 进行数据读取的这一过程中，**CPU只是需要进行缓冲区管理，以及创建和处理 DMA** ，除此之外，CPU 不需要再做更多的事情
		3. DMA 执行完数据读取操作之后，会通知操作系统做进一步的处理。
		4. Linux 操作系统会根据 read() 系统调用指定的应用程序地址空间的地址，把这块数据存放到请求这块数据的应用程序的地址空间中去
		5. 在接下来的处理过程中，操作系统需要将数据再一次从用户应用程序地址空间的缓冲区拷贝到与网络堆栈相关的内核缓冲区中去，这个过程也是**需要占用 CPU 的**。
		6. 数据拷贝操作结束以后，数据会被打包，然后发送到网络接口卡上去。在数据传输的过程中，应用程序可以先返回进而执行其他的操作。
		7. 之后，在调用 write() 系统调用的时候，用户应用程序缓冲区中的数据内容可以被安全的丢弃或者更改，因为操作系统已经在内核缓冲区中保留了一份数据拷贝，当数据被成功传送到硬件上之后，这份数据拷贝就可以被丢弃。

2. DMA介绍<br>
**TODO**

3. 零拷贝技术
	1. 介绍
		零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术。零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率。而且，零拷贝技术减少了用户应用程序地址空间和操作系统内核地址空间之间因为上下文切换而带来的开销。
	2. 零拷贝技术分类	
		1. 直接 I/O<br>
			对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输：这类零拷贝技术针对的是操作系统内核并不需要对数据进行直接处理的情况，数据可以在应用程序地址空间的缓冲区和磁盘之间直接进行传输，完全不需要 Linux 操作系统内核提供的页缓存的支持。
		2. 在数据传输的过程中，避免数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间进行拷贝。<br>
			有的时候，应用程序在数据进行传输的过程中不需要对数据进行访问，那么，将数据从 Linux 的页缓存拷贝到用户进程的缓冲区中就可以完全避免，传输的数据在页缓存中就可以得到处理。在某些特殊的情况下，这种零拷贝技术可以获得较好的性能。Linux 中提供类似的系统调用主要有 mmap()，sendfile() 以及 splice()。
		3. 对数据在 Linux 的页缓存和用户进程的缓冲区之间的传输过程进行优化。<br>
			该零拷贝技术侧重于灵活地处理数据在用户进程的缓冲区和操作系统的页缓存之间的拷贝操作。这种方法延续了传统的通信方式，但是更加灵活。在 Linux 中，该方法主要利用了写时复制技术。
	3. Java零拷贝技术的实现<br>
		TODO
	
4. 问题：IO操作对CPU的消耗是否多？

5. 参考
	1. https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/index.html
	2. https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/index.html
	3. https://www.zhihu.com/question/27734728

----

<span id = "process_thread"></span>
#### 进程与线程 [(TOP)](#home)
1. 进程
	1. 定义<br>
		进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。<br>
		进程的概念主要有两点：<br>
		1. 进程是一个实体，每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。
		2. 进程是一个“执行中的程序”，程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。
	
	2. 进程的基本状态
		1. 三种状态
			1. 阻塞态：等待某个事件的完成；
			2. 就绪态：等待系统分配处理器以便运行；
			3. 执行态：占有处理器正在运行。
		2. 进程状态的切换<br>
			![](https://github.com/yinfork/Android-Interview/blob/master/res/computer/process_state.png?raw=true)
			1. 执行态 -> 阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。
			2. 阻塞态 -> 就绪态：则是等待的条件已满足，只需分配到处理器后就能运行。
			3. 执行态 -> 就绪态：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。
			4. 就绪态 -> 执行态：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态

	3. 进程调度<br>
		调度：执行的某些时刻，内核可以决定抢占当前进程，并重新开始一个先前被抢占的进程，这就是调度（cheduling），由内核中称为调度器（cheduler）代码实现，在内核调度了一个新的进程时，它就抢占当前进程，并进行上下文切换。
		1. 调度种类<br>
			高级、中级和低级调度作业从提交开始直到完成，往往要经历下述三级调度：
			1. 高级调度：又称为作业调度，它决定把后备作业调入内存运行；
			2. 中级调度：又称为在虚拟存储器中引入，在内、外存对换区进行进程对换。
			3. 低级调度：又称为进程调度，它决定把就绪队列的某进程获得CPU；
		
		2. 非抢占式调度与抢占式调度
			1. 非抢占式：分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程。
			2. 抢占式：操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式。

		3. 调度策略的设计<br>
			CPU任务可以分为交互式任务和批处理任务，调度最终的目标是合理的使用CPU，使得交互式任务的响应时间尽可能短，用户不至于感到延迟，同时使得批处理任务的周转时间尽可能短，减少用户等待的时间。
			1. 响应时间：从用户输入到产生反应的时间
			2. 周转时间：从任务开始到任务结束的时间
			3. 平均周转时间：周转总时间除以作业个数

		4. 调度算法<br>
			TODO：略
	
	4. 进程同步
		1. 临界资源<br>
			对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。
		
		2. 访问临界资源<br>
			在操作系统中，**进程是占有资源的最小单位(线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源)**。<br>
			对于临界资源的访问，必须是互斥进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。
			对于临界区的访问过程分为四个部分：<br>
			1. 进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞
			2. 临界区:在临界区做操作
			3. 退出区:清除临界区被占用的标志
			4. 剩余区：进程与临界区不相关部分的代码
		
		3. 解决临界区问题可能的方法：
			1. 一般软件方法
			2. 关中断方法
			3. 硬件原子指令方法
			4. 信号量方法

		4. 信号量
			信号量是一个确定的二元组（s，q），其中s是一个具有非负初值的整形变量，q是一个初始状态为空的队列
			1. 整形变量s表示系统中某类资源的数目：
				1. 当其值 >= 0 时，表示系统中当前可用资源的数目
				2. 当其值 < 0 时，其绝对值表示系统中因请求该类资源而被阻塞的进程数目
			2. PV操作<br>
				除信号量的初值外，信号量的值仅能由P操作和V操作更改，操作系统利用它的状态对进程和资源进行管理
				1. P操作可以理解为分配资源的计数器，或是使进程处于等待状态的控制指令
				2. V操作可以理解为归还资源的计数器，或是唤醒进程使其处于就绪状态的控制指令

	5. 进程间通信<br>
		本地进程间通信的方式有很多，可以总结为下面四类：
		1. 消息传递（管道、FIFO、消息队列）
		2. 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）
		3. 共享内存（匿名的和具名的）
		4. 远程过程调用（Solaris门和Sun RPC）

2. 线程
	1. 定义<br>
		线程是 **操作系统能够进行运算调度的最小单位**。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务

	2. 线程的属性
		1. 轻型实体<br>
			线程的实体包括：
			1. 程序
			2. 数据
			3. 线程控制块TCB（Thread Control Block）。TCB包括以下信息：
				1. 线程状态。
				2. 当线程不运行时，被保存的现场资源。
				3. 一组执行堆栈。
				4. 存放每个线程的局部变量主存区。
				5. 访问同一个进程中的主存和其它资源。
		
		2. 独立调度和分派的基本单位：<br>
			在多线程OS中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中的）。

		3. 可并发执行：<br>
			在一个进程中的多个线程之间，可以并发执行，甚至允许在一个进程中所有线程都能并发执行；同样，不同进程中的线程也能并发执行，充分利用和发挥了处理机与外围设备并行工作的能力。

		4. 共享进程资源：<br>
			在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的地址空间（进程的地址空间），这意味着，线程可以访问该地址空间的每一个虚地址；此外，还可以访问进程所拥有的已打开文件、定时器、信号量机构等。由于同一个进程内的线程共享内存和文件，所以线程之间互相通信不必调用内核。<br>
			线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。

	3. 线程的类别
		1. 用户线程
		2. 内核线程<br>
		 	TODO
		
3. 线程和进程的区别：
	1. 调度<br>		
		在引入线程的操作系统中，线程是调度和分配的基本单位 ，进程是资源拥有的基本单位。<br>
		把传统进程的两个属性分开，线程便能轻装运行，从而可显著地提高系统的并发程度。在操作系统设计上，从进程演化出线程，最主要的目的就是更好的支持SMP(对称多处理)以及减小上下文切换开销。<br>
		在同一进程中，线程的切换不会引起进程的切换；在由一个进程中的线程切换到另一个进程中的线程时，才会引起进程的切换。
	2. 并发性<br>
		在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，因而使操作系统具有更好的并发性，从而能更有效地使用系统资源和提高系统吞吐量。
	3. 拥有资源<br>
		不论是传统的操作系统，还是设有线程的操作系统，进程都是拥有资源的一个独立单位，它可以拥有自己的资源。 一般地说，线程自己不拥有系统资源（只有一些必不可少的资源），但它可以访问其隶属进程的资源。
	4. 系统开销<br>
		由于在创建或撤消进程时，系统都要为之分配或回收资源，因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。 进程切换的开销也远大于线程切换的开销。

4. 参考
	1. http://blog.sina.com.cn/s/blog_4ae60332010005h0.html
	2. https://www.jianshu.com/p/91c8600cb2ae
	3. https://github.com/hadyang/interview/blob/master/basic/op/concurrency.md 

----

<span id = "deadlock"></span>
#### 死锁 [(TOP)](#home)
1. 定义<br>
	死锁是指多个进程因循环等待资源而造成无法执行的现象。死锁会造成进程无法执行，同时会造成系统资源的极大浪费(资源无法释放)。

2. 死锁产生的四个必要条件<br>
	这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之
一不满足，就不会发生死锁。
	1. 互斥使用：<br>
		指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。
	2. 不可抢占：<br>
		指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
	3. 请求和保持：<br>
		指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。
	4. 循环等待：<br>
		指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。

3. 死锁的例子

	```
	public class DeadLockDemo {
	
	    public static void main(String[] args) {
	        // 线程a
	        Thread td1 = new Thread(new Runnable() {
	            public void run() {
	                DeadLockDemo.method1();
	            }
	        });
	        // 线程b
	        Thread td2 = new Thread(new Runnable() {
	            public void run() {
	                DeadLockDemo.method2();
	            }
	        });
	
	        td1.start();
	        td2.start();
	    }
	
	    public static void method1() {
	        synchronized (String.class) {
	            try {
	                Thread.sleep(2000);
	            } catch (InterruptedException e) {
	                e.printStackTrace();
	            }
	            System.out.println("线程a尝试获取integer.class");
	            synchronized (Integer.class) {
	
	            }
	
	        }
	    }
	
	    public static void method2() {
	        synchronized (Integer.class) {
	            try {
	                Thread.sleep(2000);
	            } catch (InterruptedException e) {
	                e.printStackTrace();
	            }
	            System.out.println("线程b尝试获取String.class");
	            synchronized (String.class) {
	
	            }
	
	        }
	    }
	
	}
	
	----------------
	线程b尝试获取String.class
	线程a尝试获取integer.class
	....
	...
	..
	.
	无限阻塞下去
	
	```

4. 死锁避免<br>
	在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确定资源的合理分配算法，避免进程永久占据系统资源。此外，也要防止进程在处于等待状态的情况下占用资源。因此，对资源的分配要给予合理的规划。<br>
	简单来说：在并发程序中，避免逻辑中出现多个线程互相持有对方线程所需要的独占锁的的情况，就可以避免死锁。

5. 死锁避免的算法<br>
	1. 银行家算法
		1. 说明<br>
			在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。
		2. 小结<br>
			判断此次请求是否造成死锁，若会造成死锁，则拒绝该请求。

6. 参考
	1. https://blog.csdn.net/Roy_70/article/details/50958513
	2. https://www.nowcoder.com/questionTerminal/09b51b00891543d6b08ace80c0704b01
	3. https://github.com/hadyang/interview/blob/master/basic/op/concurrency.md

----

<span id = "encrypt"></span>
#### 加密算法 [(TOP)](#home)
1. 对称加密
	1. 定义
		指的就是加、解密使用的同是一串密钥，所以被称做对称加密。对称加密只有一个密钥作为私钥。 
	
	2. 常见的对称加密算法：DES，AES等。

	3. 优点
		对称加密相比非对称加密算法来说，加解密的效率要高得多、加密速度快。
		
	4. 缺点
		缺陷在于对于密钥的管理和分发上比较困难，不是非常安全，密钥管理负担很重。

2. 非对称加密
	1. 定义
		指的是加、解密使用不同的密钥，一把作为公开的公钥，另一把作为私钥。公钥加密的信息，只有私钥才能解密。反之，私钥加密的信息，只有公钥才能解密。 <br>
		举个例子，你向某公司服务器请求公钥，服务器将公钥发给你，你使用公钥对消息加密，那么只有私钥的持有人才能对你的消息解密。与对称加密不同的是，公司服务器不需要将私钥通过网络发送出去，因此安全性大大提高。
	
	2. 最常用的非对称加密算法：RSA

	3. 优点
		安全性更高，公钥是公开的，密钥是自己保存的，不需要将私钥给别人
	
	4. 缺点
		加密和解密花费时间长、速度慢，只适合对少量数据进行加密。

3. 对称加密和非对称加密混合使用<br>
	将对称加密的密钥使用非对称加密的公钥进行加密，然后发送出去，接收方使用私钥进行解密得到对称加密的密钥，然后双方可以使用对称加密来进行沟通。



